{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b608145e",
   "metadata": {},
   "source": [
    "# Buirning Rate & Elements Consuming Time (xDays) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6bf1128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from seaborn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (1.23.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: dtale in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: dash-colorscales in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.0.4)\n",
      "Requirement already satisfied: dash-daq in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.5.0)\n",
      "Requirement already satisfied: Flask-Compress in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.13)\n",
      "Requirement already satisfied: future>=0.14.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.18.3)\n",
      "Requirement already satisfied: missingno<=0.4.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.5.1)\n",
      "Requirement already satisfied: squarify in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.4.3)\n",
      "Requirement already satisfied: strsimpy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.2.1)\n",
      "Requirement already satisfied: six in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.16.0)\n",
      "Requirement already satisfied: xlrd in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.0.1)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (4.11.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2021.10.8)\n",
      "Requirement already satisfied: cycler in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.11.0)\n",
      "Requirement already satisfied: flask-ngrok in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.0.25)\n",
      "Requirement already satisfied: lz4 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (4.3.2)\n",
      "Requirement already satisfied: dash>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.8.1)\n",
      "Requirement already satisfied: dash-bootstrap-components<=1.3.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.3.1)\n",
      "Requirement already satisfied: kaleido in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.2.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.1.3)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.13.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.23.4)\n",
      "Requirement already satisfied: openpyxl!=3.2.0b1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (3.1.2)\n",
      "Requirement already satisfied: xarray in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2023.2.0)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.1.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (5.13.1)\n",
      "Requirement already satisfied: Flask in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.1.2)\n",
      "Requirement already satisfied: requests in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.27.1)\n",
      "Requirement already satisfied: scipy==1.9.3 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.9.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (1.0.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (2.8.2)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dash>=2.0.0->dtale) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dash>=2.0.0->dtale) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dash>=2.0.0->dtale) (5.0.0)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (4.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from plotly>=5.0.0->dtale) (8.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from beautifulsoup4->dtale) (2.4)\n",
      "Requirement already satisfied: brotli in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask-Compress->dtale) (1.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas->dtale) (2022.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from requests->dtale) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from requests->dtale) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from requests->dtale) (3.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn->dtale) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn->dtale) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from statsmodels->dtale) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from click>=8.0->Flask->dtale) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask->dtale) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Jinja2>=3.0->Flask->dtale) (2.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.2.13)\n",
      "Requirement already satisfied: numpy<1.25,>=1.21.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.23.4)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.1.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.5.1)\n",
      "Requirement already satisfied: scikit-learn<1.3.0,>=0.24.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.1.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.9.3)\n",
      "Requirement already satisfied: numba>=0.53 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (0.56.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from deprecated>=1.2.13->sktime) (1.15.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.53->sktime) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.53->sktime) (58.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas<1.6.0,>=1.1.0->sktime) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas<1.6.0,>=1.1.0->sktime) (2022.6)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.1.0->sktime) (1.16.0)\n",
      "Requirement already satisfied: sklego in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-lego in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sklego) (0.6.14)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.1.3)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.5.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (0.5.3)\n",
      "Requirement already satisfied: autograd>=1.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.5)\n",
      "Requirement already satisfied: Deprecated>=1.2.6 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.2.13)\n",
      "Requirement already satisfied: umap-learn>=0.4.6 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.12 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from autograd>=1.2->scikit-lego->sklego) (1.23.4)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from autograd>=1.2->scikit-lego->sklego) (0.18.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Deprecated>=1.2.6->scikit-lego->sklego) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego->sklego) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego->sklego) (2022.6)\n",
      "Requirement already satisfied: six in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from patsy>=0.5.1->scikit-lego->sklego) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.24.1->scikit-lego->sklego) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.24.1->scikit-lego->sklego) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.24.1->scikit-lego->sklego) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from umap-learn>=0.4.6->scikit-lego->sklego) (0.56.4)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from umap-learn>=0.4.6->scikit-lego->sklego) (0.5.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from umap-learn>=0.4.6->scikit-lego->sklego) (4.63.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego->sklego) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego->sklego) (58.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from tqdm->umap-learn>=0.4.6->scikit-lego->sklego) (0.4.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (13.3.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from rich) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from rich) (2.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich) (0.1.2)\n",
      "Requirement already satisfied: pip in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (23.1)\n"
     ]
    }
   ],
   "source": [
    "### ***Enviroment Preparation***\n",
    "# Install Pandas\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "\n",
    "!pip install dtale\n",
    "\n",
    "!pip install sktime\n",
    "!pip install sklego\n",
    "\n",
    "!pip install rich\n",
    "#!pip install skforecast\n",
    "\n",
    "# Update pip -- WARNING Resolution\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158a2663",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***Imports***\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import time\n",
    "from datetime import date\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "import dtale\n",
    "from rich.progress import track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834af3e4",
   "metadata": {},
   "source": [
    "# Recopilar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3a8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data = r\"C:\\Users\\ghoyo\\Desktop\\TFM 3.0\\Project\\GeneratedDfs\\VisualsData.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e237c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2071239",
   "metadata": {},
   "source": [
    "# Investigar Y Limpiar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4819a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82028, 32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2431db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 82028 entries, 0 to 82027\n",
      "Data columns (total 32 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   platform                           82028 non-null  object        \n",
      " 1   master_metadata_track_name         82028 non-null  object        \n",
      " 2   master_metadata_album_artist_name  82028 non-null  object        \n",
      " 3   master_metadata_album_album_name   82028 non-null  object        \n",
      " 4   spotify_track_uri                  82028 non-null  object        \n",
      " 5   reason_start                       82028 non-null  object        \n",
      " 6   reason_end                         82028 non-null  object        \n",
      " 7   is_song                            82028 non-null  int64         \n",
      " 8   is_podcast                         82028 non-null  int64         \n",
      " 9   end_streaming                      82028 non-null  int64         \n",
      " 10  s_played                           82028 non-null  int64         \n",
      " 11  end_streaming_seconds              82028 non-null  int64         \n",
      " 12  start_streaming_seconds            82028 non-null  int64         \n",
      " 13  start_streaming                    82028 non-null  int64         \n",
      " 14  delta_time                         82028 non-null  int64         \n",
      " 15  year                               82028 non-null  int64         \n",
      " 16  seasson                            82028 non-null  int64         \n",
      " 17  month                              82028 non-null  int64         \n",
      " 18  month_and_year                     82028 non-null  object        \n",
      " 19  week                               82028 non-null  int64         \n",
      " 20  week_and_year                      82028 non-null  object        \n",
      " 21  day                                82028 non-null  int64         \n",
      " 22  days_to_next_month                 82028 non-null  int64         \n",
      " 23  date                               82028 non-null  datetime64[ns]\n",
      " 24  hour                               82028 non-null  int64         \n",
      " 25  minute                             82028 non-null  int64         \n",
      " 26  second                             82028 non-null  int64         \n",
      " 27  time                               82028 non-null  object        \n",
      " 28  str_time                           82028 non-null  datetime64[ns]\n",
      " 29  time_in_s                          82028 non-null  int64         \n",
      " 30  week_day                           82028 non-null  int64         \n",
      " 31  df_fractured                       82028 non-null  int64         \n",
      "dtypes: datetime64[ns](2), int64(20), object(10)\n",
      "memory usage: 20.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5ce98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>master_metadata_track_name</th>\n",
       "      <th>master_metadata_album_artist_name</th>\n",
       "      <th>master_metadata_album_album_name</th>\n",
       "      <th>spotify_track_uri</th>\n",
       "      <th>reason_start</th>\n",
       "      <th>reason_end</th>\n",
       "      <th>is_song</th>\n",
       "      <th>is_podcast</th>\n",
       "      <th>end_streaming</th>\n",
       "      <th>...</th>\n",
       "      <th>days_to_next_month</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>time</th>\n",
       "      <th>str_time</th>\n",
       "      <th>time_in_s</th>\n",
       "      <th>week_day</th>\n",
       "      <th>df_fractured</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Excesos</td>\n",
       "      <td>Natos y Waor</td>\n",
       "      <td>Caja Negra</td>\n",
       "      <td>spotify:track:1bp8LR3mPRlHs0dOZGNHm3</td>\n",
       "      <td>fwdbtn</td>\n",
       "      <td>endplay</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1491312576000</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>36</td>\n",
       "      <td>13:29:36</td>\n",
       "      <td>2023-04-21 13:29:36</td>\n",
       "      <td>48576</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Calavera no chilla</td>\n",
       "      <td>Natos y Waor</td>\n",
       "      <td>Calavera no chilla</td>\n",
       "      <td>spotify:track:5dgA6aIoYJvTz48qAI0rPf</td>\n",
       "      <td>clickrow</td>\n",
       "      <td>logout</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1491314816000</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>14:06:56</td>\n",
       "      <td>2023-04-21 14:06:56</td>\n",
       "      <td>50816</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Metacrilato</td>\n",
       "      <td>Ayax y Prok</td>\n",
       "      <td>Metacrilato</td>\n",
       "      <td>spotify:track:5z5Q95JbFva9DcKnshOgiU</td>\n",
       "      <td>appload</td>\n",
       "      <td>logout</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1491314927000</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>14:08:47</td>\n",
       "      <td>2023-04-21 14:08:47</td>\n",
       "      <td>50927</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phone</td>\n",
       "      <td>Metacrilato</td>\n",
       "      <td>Ayax y Prok</td>\n",
       "      <td>Metacrilato</td>\n",
       "      <td>spotify:track:5z5Q95JbFva9DcKnshOgiU</td>\n",
       "      <td>appload</td>\n",
       "      <td>trackdone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1491315024000</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>14:10:24</td>\n",
       "      <td>2023-04-21 14:10:24</td>\n",
       "      <td>51024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phone</td>\n",
       "      <td>La flauta de Hamelin</td>\n",
       "      <td>Ayax y Prok</td>\n",
       "      <td>Albayzín Recopilatorio</td>\n",
       "      <td>spotify:track:1XnG8fGed91t2U061Xb5gZ</td>\n",
       "      <td>clickrow</td>\n",
       "      <td>endplay</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1491315271000</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>14:14:31</td>\n",
       "      <td>2023-04-21 14:14:31</td>\n",
       "      <td>51271</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  platform master_metadata_track_name master_metadata_album_artist_name  \\\n",
       "0    Phone                    Excesos                      Natos y Waor   \n",
       "1    Phone         Calavera no chilla                      Natos y Waor   \n",
       "2    Phone                Metacrilato                       Ayax y Prok   \n",
       "3    Phone                Metacrilato                       Ayax y Prok   \n",
       "4    Phone       La flauta de Hamelin                       Ayax y Prok   \n",
       "\n",
       "  master_metadata_album_album_name                     spotify_track_uri  \\\n",
       "0                       Caja Negra  spotify:track:1bp8LR3mPRlHs0dOZGNHm3   \n",
       "1               Calavera no chilla  spotify:track:5dgA6aIoYJvTz48qAI0rPf   \n",
       "2                      Metacrilato  spotify:track:5z5Q95JbFva9DcKnshOgiU   \n",
       "3                      Metacrilato  spotify:track:5z5Q95JbFva9DcKnshOgiU   \n",
       "4           Albayzín Recopilatorio  spotify:track:1XnG8fGed91t2U061Xb5gZ   \n",
       "\n",
       "  reason_start reason_end  is_song  is_podcast  end_streaming  ...  \\\n",
       "0       fwdbtn    endplay        1           0  1491312576000  ...   \n",
       "1     clickrow     logout        1           0  1491314816000  ...   \n",
       "2      appload     logout        1           0  1491314927000  ...   \n",
       "3      appload  trackdone        1           0  1491315024000  ...   \n",
       "4     clickrow    endplay        1           0  1491315271000  ...   \n",
       "\n",
       "   days_to_next_month       date  hour  minute  second      time  \\\n",
       "0                  26 2017-04-04    13      29      36  13:29:36   \n",
       "1                  26 2017-04-04    14       6      56  14:06:56   \n",
       "2                  26 2017-04-04    14       8      47  14:08:47   \n",
       "3                  26 2017-04-04    14      10      24  14:10:24   \n",
       "4                  26 2017-04-04    14      14      31  14:14:31   \n",
       "\n",
       "             str_time  time_in_s week_day  df_fractured  \n",
       "0 2023-04-21 13:29:36      48576        1             0  \n",
       "1 2023-04-21 14:06:56      50816        1             0  \n",
       "2 2023-04-21 14:08:47      50927        1             0  \n",
       "3 2023-04-21 14:10:24      51024        1             0  \n",
       "4 2023-04-21 14:14:31      51271        1             0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa394db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data transformations\n",
    "def transform_time(df):\n",
    "    df['time'] = df['time'].apply(lambda x: datetime.strptime(x, '%H:%M:%S').time())\n",
    "def transform_date(df):\n",
    "    df['date'] = df['date'].apply(lambda x: date(x.year, x.month, x.day))\n",
    "\n",
    "def generate_end_streaming(df):\n",
    "    transform_time(df)\n",
    "    #transform_date(df)\n",
    "    df['end_streaming'] = df.apply(lambda x: rt_dt(x['date'], x['time']), axis=1)\n",
    "\n",
    "\n",
    "def rt_dt(dfdate, dftime):\n",
    "    return datetime(dfdate.year, dfdate.month, dfdate.day, dftime.hour, dftime.minute, dftime.second) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37594cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.41 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generate_end_streaming(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ff37c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2017-04-04 13:29:36\n",
       "1   2017-04-04 14:06:56\n",
       "Name: end_streaming, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['end_streaming'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a52d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new usefull column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "356cc203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['week_and_year'] = df['end_streaming'].apply(lambda x : (x.year, x.week))\n",
    "df['week_and_year'] = df['week_and_year'].apply(lambda x: '-'.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04823373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2017-14\n",
       "1    2017-14\n",
       "Name: week_and_year, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['week_and_year'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e73568",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = df[['end_streaming', 'master_metadata_track_name', 'is_song', 'week_and_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7ad7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.drop_duplicates()\n",
    "dfi.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "202d890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_streaming</th>\n",
       "      <th>master_metadata_track_name</th>\n",
       "      <th>is_song</th>\n",
       "      <th>week_and_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-04 13:29:36</td>\n",
       "      <td>Excesos</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-04 14:06:56</td>\n",
       "      <td>Calavera no chilla</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-04 14:08:47</td>\n",
       "      <td>Metacrilato</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-04 14:10:24</td>\n",
       "      <td>Metacrilato</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-04 14:14:31</td>\n",
       "      <td>La flauta de Hamelin</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        end_streaming master_metadata_track_name  is_song week_and_year\n",
       "0 2017-04-04 13:29:36                    Excesos        1       2017-14\n",
       "1 2017-04-04 14:06:56         Calavera no chilla        1       2017-14\n",
       "2 2017-04-04 14:08:47                Metacrilato        1       2017-14\n",
       "3 2017-04-04 14:10:24                Metacrilato        1       2017-14\n",
       "4 2017-04-04 14:14:31       La flauta de Hamelin        1       2017-14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f12ea2",
   "metadata": {},
   "source": [
    "#### Get unique Streams list & Dataset of this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67192b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_stream_list = df['master_metadata_track_name'].unique()\n",
    "    #drop_df = df.drop_duplicates(subset = ['master_metadata_track_name', 'week_and_year'])\n",
    "    #print(drop_df['master_metadata_track_name'].value_counts()['Insoportables'])\n",
    "\n",
    "# Get week Index Lists\n",
    "u_week_list = df['week_and_year'].unique()\n",
    "week_list = [df[df['week_and_year'] == w].index for w in u_week_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "523e2fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Excesos', 'Calavera no chilla', 'Metacrilato', ...,\n",
       "       'somehow she’s still here (feat. James Blake)',\n",
       "       'WHY AM I STILL IN LA (feat. Shlohmo & D33J)', 'je suis'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(u_stream_list))\n",
    "u_stream_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61c10b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "['2017-14' '2017-15' '2017-16' '2017-17' '2017-18' '2017-19' '2017-20'\n",
      " '2017-21' '2017-22' '2017-23' '2017-24' '2017-25' '2017-26' '2017-27'\n",
      " '2017-28' '2017-29' '2017-30' '2017-31' '2017-32' '2017-33']\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(len(u_week_list))\n",
    "print(u_week_list[:20]) \n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0fecb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "389\n",
      "Int64Index([389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401,\n",
      "            402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414,\n",
      "            415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427,\n",
      "            428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440,\n",
      "            441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453,\n",
      "            454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466,\n",
      "            467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479],\n",
      "           dtype='int64')\n",
      "[389, 91, 328, 231, 251, 213, 455, 486, 395, 225, 148, 247, 102, 268, 322, 244, 194, 190, 301, 477, 485, 262, 271, 211, 247, 221, 238, 305, 419, 250, 345, 474, 291, 235, 380, 455, 539, 410, 339, 152, 324, 281, 363, 285, 250, 326, 388, 295, 359, 226, 380, 480, 215, 163, 237, 274, 401, 307, 150, 235, 240, 278, 196, 249, 197, 177, 242, 766, 328, 253, 384, 168, 250, 236, 139, 241, 200, 213, 173, 222, 374, 297, 200, 181, 176, 276, 243, 167, 360, 327, 233, 268, 265, 274, 289, 333, 296, 319, 300, 261, 326, 279, 260, 330, 339, 320, 365, 442, 307, 377, 496, 402, 356, 540, 303, 212, 292, 243, 246, 58, 244, 279, 411, 244, 289, 330, 403, 250, 261, 286, 306, 223, 229, 217, 316, 298, 305, 204, 383, 398, 351, 466, 338, 274, 459, 338, 335, 424, 289, 255, 257, 326, 362, 286, 71, 163, 261, 384, 178, 291, 391, 347, 385, 316, 365, 614, 481, 477, 445, 527, 628, 460, 567, 467, 639, 265, 531, 275, 643, 430, 511, 233, 432, 363, 352, 300, 262, 182, 319, 178, 207, 284, 150, 216, 301, 91, 129, 117, 275, 338, 377, 288, 245, 243, 198, 225, 207, 176, 258, 288, 257, 296, 146, 287, 242, 207, 212, 303, 426, 294, 108, 481, 198, 188, 314, 162, 356, 197, 279, 161, 148, 146, 186, 178, 91, 199, 323, 286, 174, 184, 146, 203, 224, 238, 276, 290, 257, 236, 148, 61, 265, 338, 290, 222, 156, 247, 267, 162, 290, 224, 309, 130, 380, 223, 296, 137, 343, 166, 211, 154, 191, 147, 227, 198, 158, 138, 81, 152, 114, 114, 141, 202, 107, 128, 106, 349, 69, 83, 295, 244, 107, 92, 91, 210, 142, 61, 72] \n",
      "\n",
      "276.1885521885522\n"
     ]
    }
   ],
   "source": [
    "print(len(week_list))\n",
    "print(len(week_list[0]))\n",
    "print(week_list[1])\n",
    "\n",
    "week_list_mean = [len(w) for w in week_list]\n",
    "print(week_list_mean, '\\n')\n",
    "\n",
    "print(np.mean(week_list_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65028755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32fab757c10343aca2ff75755ed991e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 52min 23s\n",
      "Wall time: 2h 18min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Generate Result Variables\n",
    "sec_streamed = []\n",
    "num_streamed = []\n",
    "ix_list = []\n",
    "\n",
    "s_sec_streamed = []\n",
    "s_num_streamed = []\n",
    "s_ix_list = []\n",
    "\n",
    "ix_aux_list = []\n",
    "sec = 0\n",
    "num = 0\n",
    "\n",
    "# loop to get streak of streams during weeks\n",
    "for s in track(u_stream_list, description='Search for all Streams'):\n",
    "    for wi in week_list:\n",
    "        for i in wi:\n",
    "            if (s == df.loc[i, 'master_metadata_track_name']):\n",
    "                # Extract full Week Data\n",
    "                ix_aux_list.append(i)\n",
    "                sec = sec + df.loc[i, 's_played']\n",
    "                num = num+1\n",
    "        \n",
    "        # Save Single Stream Data\n",
    "        s_sec_streamed.append(sec)\n",
    "        s_num_streamed.append(num)\n",
    "        if(len(ix_aux_list) != 0):\n",
    "            s_ix_list.append(ix_aux_list)\n",
    "        \n",
    "        # Clean Aux Vars\n",
    "        ix_aux_list = []\n",
    "        sec = 0\n",
    "        num = 0\n",
    "    \n",
    "    # Save All Streams Stream Data\n",
    "    sec_streamed.append(s_sec_streamed)\n",
    "    num_streamed.append(s_num_streamed)\n",
    "    ix_list.append(s_ix_list)\n",
    "\n",
    "    # Clean Single Stream Vars\n",
    "    s_sec_streamed = []\n",
    "    s_num_streamed = []\n",
    "    s_ix_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fc692d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297\n",
      "14082\n"
     ]
    }
   ],
   "source": [
    "#sec_streamed\n",
    "#ix_list\n",
    "n_weeks = len(num_streamed[0])\n",
    "print(n_weeks)\n",
    "num_streamed[-1][n_weeks-1]\n",
    "\n",
    "# N Streams \n",
    "n_streams = len(df['master_metadata_track_name'].unique())\n",
    "print(n_streams)\n",
    "stream_list = df['master_metadata_track_name'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f6a635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Excesos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calavera no chilla</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metacrilato</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La flauta de Hamelin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000 Clavos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Need4Speed - Fumado y Hambriento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOODS HOTTEST</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somehow she’s still here (feat. James Blake)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHY AM I STILL IN LA (feat. Shlohmo &amp; D33J)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>je suis</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14082 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [Excesos, Calavera no chilla, Metacrilato, La flauta de Hamelin, 2000 Clavos, Echo de menos, Felicidad, Carne de cañón, The Right Song, You Know, I Don't Wanna Go Home, Good Life, Puedo solo, Orgullo y prejuicio, Saludos, Alas Rotas, 蓝 - Cuéntamelo, Marketing, Terciopelo, Orgullo Banderillero, El Idioma De Los Dioses, Veneno, Menos, A Lo Mejor, Consentía - El Corte Remix, Sakalakalashnikov, Te conozco bien, U, My Friend, Without You (feat. The Galaxy & Gia Koka), Love & War (feat. Yade Lauren), Me Rehúso, Lumbra, Fuego, Sigo Extrañándote, Heatstroke (feat. Young Thug, Pharrell Williams & Ariana Grande), Simplecito, Good Girls, In Cold Blood, Lean On (feat. MØ & DJ Snake), Bad Man - Skrillex Remix, You & Me - Baauer Remix, Pompeii - Audien Remix, La Vida Es, Te Amo Sin Límites, Mazas y Catapultas, Cuando sale el sol, Cantando, Drop the Beat - Radio Edit, Traicionera, Me llamas (feat. Maluma) - Remix, Desde Que Estamos Juntos, Deja vu, Shape of You, Something Just Like This, Ando buscando (feat. Piso 21), Chantaje, La Bicicleta, Manicomio, Can't Feel My Face, Deep Inside - Low Steppa Remix, Sun Is Shining, Firestone, Say My Name (feat. Zyra), Elastic Heart, Hey Ma (with Pitbull & J Balvin feat. Camila Cabello), HUMBLE., Passionfruit, Swalla (feat. Nicki Minaj & Ty Dolla $ign), Mask Off, Free Smoke, Swang, Bad and Boujee (feat. Lil Uzi Vert), Tierra de bandios, Cutting Shapes, Good For You, Dynamite (feat. Pretty Sister), Take My Hand, Azulejos de Corales, Jaquetona, Dame Luz, I Love You, Anywhere You Go (feat. Timmy Trumpet), The Hum - Short Edit, In the Name of Love - DallasK Remix, Do It Right, Sing2Me, Rolling Stones T-Shirt, Cubata - Breakdown Remix, Rockabye (feat. Sean Paul & Anne-Marie), Deja Que Te Bese, Scared to Be Lonely, Sé Que Te Duele, Stay (with Alessia Cara), It Ain't Me (with Selena Gomez), Vacaciones, La Rompe Corazones, Sola (Remix), Shape of You (feat. Zion & Lennox) - Latin Remix, Bailame Despacio, ...]\n",
       "\n",
       "[14082 rows x 0 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "num_df = pd.DataFrame(index = df['master_metadata_track_name'].unique())\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b8cc176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9a59804e5b4d3caaddc55539b55c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\1378283885.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>...</th>\n",
       "      <th>w287</th>\n",
       "      <th>w288</th>\n",
       "      <th>w289</th>\n",
       "      <th>w290</th>\n",
       "      <th>w291</th>\n",
       "      <th>w292</th>\n",
       "      <th>w293</th>\n",
       "      <th>w294</th>\n",
       "      <th>w295</th>\n",
       "      <th>w296</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Excesos</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calavera no chilla</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metacrilato</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La flauta de Hamelin</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000 Clavos</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        w0   w1    w2    w3    w4   w5   w6    w7   w8   w9  \\\n",
       "Excesos                1.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "Calavera no chilla    25.0  4.0  36.0  17.0   8.0  2.0  4.0  10.0  0.0  0.0   \n",
       "Metacrilato           40.0  3.0  39.0  26.0  13.0  4.0  4.0   8.0  0.0  1.0   \n",
       "La flauta de Hamelin   3.0  0.0   1.0   3.0   2.0  0.0  0.0   0.0  1.0  0.0   \n",
       "2000 Clavos            3.0  0.0   0.0   0.0   0.0  0.0  0.0   0.0  0.0  0.0   \n",
       "\n",
       "                      ...  w287  w288  w289  w290  w291  w292  w293  w294  \\\n",
       "Excesos               ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "Calavera no chilla    ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "Metacrilato           ...   0.0   0.0   0.0   0.0   1.0   0.0   0.0   0.0   \n",
       "La flauta de Hamelin  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2000 Clavos           ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                      w295  w296  \n",
       "Excesos                0.0   0.0  \n",
       "Calavera no chilla     0.0   0.0  \n",
       "Metacrilato            0.0   0.0  \n",
       "La flauta de Hamelin   0.0   0.0  \n",
       "2000 Clavos            0.0   0.0  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Columns:\n",
    "cols = []\n",
    "for w,i in zip(num_streamed[0], range(n_weeks)):\n",
    "     cols.append(''.join(('w',str(i))))\n",
    "\n",
    "num_df[cols] = np.nan\n",
    "\n",
    "# Insert info at each column\n",
    "for s,i in track(zip(num_streamed, range(n_streams)), description='Completing Dataset'):\n",
    "    for w,c in zip(s, cols):\n",
    "        num_df.loc[stream_list[i], c] = w\n",
    "\n",
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b698ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>...</th>\n",
       "      <th>w287</th>\n",
       "      <th>w288</th>\n",
       "      <th>w289</th>\n",
       "      <th>w290</th>\n",
       "      <th>w291</th>\n",
       "      <th>w292</th>\n",
       "      <th>w293</th>\n",
       "      <th>w294</th>\n",
       "      <th>w295</th>\n",
       "      <th>w296</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Need4Speed - Fumado y Hambriento</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOODS HOTTEST</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somehow she’s still here (feat. James Blake)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHY AM I STILL IN LA (feat. Shlohmo &amp; D33J)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>je suis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               w0   w1   w2   w3   w4   w5  \\\n",
       "Need4Speed - Fumado y Hambriento              0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "HOODS HOTTEST                                 0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "somehow she’s still here (feat. James Blake)  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)   0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "je suis                                       0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                                               w6   w7   w8   w9  ...  w287  \\\n",
       "Need4Speed - Fumado y Hambriento              0.0  0.0  0.0  0.0  ...   0.0   \n",
       "HOODS HOTTEST                                 0.0  0.0  0.0  0.0  ...   0.0   \n",
       "somehow she’s still here (feat. James Blake)  0.0  0.0  0.0  0.0  ...   0.0   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)   0.0  0.0  0.0  0.0  ...   0.0   \n",
       "je suis                                       0.0  0.0  0.0  0.0  ...   0.0   \n",
       "\n",
       "                                              w288  w289  w290  w291  w292  \\\n",
       "Need4Speed - Fumado y Hambriento               0.0   0.0   0.0   0.0   0.0   \n",
       "HOODS HOTTEST                                  0.0   0.0   0.0   0.0   0.0   \n",
       "somehow she’s still here (feat. James Blake)   0.0   0.0   0.0   0.0   0.0   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)    0.0   0.0   0.0   0.0   0.0   \n",
       "je suis                                        0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                                              w293  w294  w295  w296  \n",
       "Need4Speed - Fumado y Hambriento               0.0   0.0   0.0   1.0  \n",
       "HOODS HOTTEST                                  0.0   0.0   0.0   1.0  \n",
       "somehow she’s still here (feat. James Blake)   0.0   0.0   0.0   1.0  \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)    0.0   0.0   0.0   1.0  \n",
       "je suis                                        0.0   0.0   0.0   2.0  \n",
       "\n",
       "[5 rows x 297 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0071c62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n"
     ]
    }
   ],
   "source": [
    "l = len(num_df.columns)-1\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a89744dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\2493253983.py:5: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\ghoyo\\AppData\\Local\\Temp\\ipykernel_14500\\2493253983.py:6: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ignorar semanas con 0 si es Semana donde se escucha por primera vez\n",
    "first_flag = 0\n",
    "last_flag = 0\n",
    "\n",
    "num_df['first_listened'] = np.nan\n",
    "num_df['last_listened'] = np.nan\n",
    "\n",
    "# First Listened\n",
    "for s in stream_list:\n",
    "    for w,i in zip(num_df.columns[:-2], range(n_weeks)):\n",
    "        if(i == 0 and num_df.loc[s, w] == 0):\n",
    "            first_flag = 0\n",
    "        \n",
    "        elif(i != 0 and num_df.loc[s, w] == 0 and first_flag == 0):\n",
    "            first_flag = 0\n",
    "        \n",
    "        elif(i != 0 and num_df.loc[s, w] != 0):\n",
    "            num_df.loc[s, 'first_listened'] = i\n",
    "            break\n",
    "        \n",
    "        elif(i == 0 and num_df.loc[s,w] != 0):\n",
    "            num_df.loc[s, 'first_listened'] = i\n",
    "            break\n",
    "        \n",
    "        elif(w == num_df.columns[:-2][-1]):\n",
    "            num_df.loc[s, 'first_listened'] = i\n",
    "\n",
    "# Last Listened\n",
    "# Reverse Dataset\n",
    "rev_n_df = num_df.iloc[:, ::-1]\n",
    "\n",
    "for s in stream_list:\n",
    "    for w,i in zip(rev_n_df.columns[2:], range(n_weeks)):\n",
    "        if(i == 0 and rev_n_df.loc[s, w] == 0):\n",
    "            last_flag = 0\n",
    "        \n",
    "        elif(i != 0 and rev_n_df.loc[s, w] == 0 and last_flag == 0):\n",
    "            last_flag = 0\n",
    "        \n",
    "        elif(i != 0 and rev_n_df.loc[s, w] != 0):\n",
    "            num_df.loc[s, 'last_listened'] = n_weeks-i\n",
    "            break\n",
    "        \n",
    "        elif(i == 0 and rev_n_df.loc[s,w] != 0):\n",
    "            num_df.loc[s, 'last_listened'] = n_weeks-i\n",
    "            break\n",
    "        \n",
    "        elif(w == rev_n_df.columns[2:][-1]):\n",
    "            num_df.loc[s, 'last_listened'] = n_weeks-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80dac456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['last_listened', 'first_listened', 'w296', 'w295', 'w294', 'w293',\n",
       "       'w292', 'w291', 'w290', 'w289',\n",
       "       ...\n",
       "       'w9', 'w8', 'w7', 'w6', 'w5', 'w4', 'w3', 'w2', 'w1', 'w0'],\n",
       "      dtype='object', length=299)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_n_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05dda49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14082 entries, Excesos to je suis\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   first_listened  14082 non-null  float64\n",
      " 1   last_listened   14082 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 846.1+ KB\n"
     ]
    }
   ],
   "source": [
    "num_df[['first_listened', 'last_listened']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5940d7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w0</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>...</th>\n",
       "      <th>w289</th>\n",
       "      <th>w290</th>\n",
       "      <th>w291</th>\n",
       "      <th>w292</th>\n",
       "      <th>w293</th>\n",
       "      <th>w294</th>\n",
       "      <th>w295</th>\n",
       "      <th>w296</th>\n",
       "      <th>first_listened</th>\n",
       "      <th>last_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Excesos</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calavera no chilla</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metacrilato</th>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>La flauta de Hamelin</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000 Clavos</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Need4Speed - Fumado y Hambriento</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOODS HOTTEST</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>somehow she’s still here (feat. James Blake)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHY AM I STILL IN LA (feat. Shlohmo &amp; D33J)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>je suis</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14082 rows × 299 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                w0   w1    w2    w3    w4  \\\n",
       "Excesos                                        1.0  0.0   0.0   0.0   0.0   \n",
       "Calavera no chilla                            25.0  4.0  36.0  17.0   8.0   \n",
       "Metacrilato                                   40.0  3.0  39.0  26.0  13.0   \n",
       "La flauta de Hamelin                           3.0  0.0   1.0   3.0   2.0   \n",
       "2000 Clavos                                    3.0  0.0   0.0   0.0   0.0   \n",
       "...                                            ...  ...   ...   ...   ...   \n",
       "Need4Speed - Fumado y Hambriento               0.0  0.0   0.0   0.0   0.0   \n",
       "HOODS HOTTEST                                  0.0  0.0   0.0   0.0   0.0   \n",
       "somehow she’s still here (feat. James Blake)   0.0  0.0   0.0   0.0   0.0   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)    0.0  0.0   0.0   0.0   0.0   \n",
       "je suis                                        0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "                                               w5   w6    w7   w8   w9  ...  \\\n",
       "Excesos                                       0.0  0.0   0.0  0.0  0.0  ...   \n",
       "Calavera no chilla                            2.0  4.0  10.0  0.0  0.0  ...   \n",
       "Metacrilato                                   4.0  4.0   8.0  0.0  1.0  ...   \n",
       "La flauta de Hamelin                          0.0  0.0   0.0  1.0  0.0  ...   \n",
       "2000 Clavos                                   0.0  0.0   0.0  0.0  0.0  ...   \n",
       "...                                           ...  ...   ...  ...  ...  ...   \n",
       "Need4Speed - Fumado y Hambriento              0.0  0.0   0.0  0.0  0.0  ...   \n",
       "HOODS HOTTEST                                 0.0  0.0   0.0  0.0  0.0  ...   \n",
       "somehow she’s still here (feat. James Blake)  0.0  0.0   0.0  0.0  0.0  ...   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)   0.0  0.0   0.0  0.0  0.0  ...   \n",
       "je suis                                       0.0  0.0   0.0  0.0  0.0  ...   \n",
       "\n",
       "                                              w289  w290  w291  w292  w293  \\\n",
       "Excesos                                        0.0   0.0   0.0   0.0   0.0   \n",
       "Calavera no chilla                             0.0   0.0   0.0   0.0   0.0   \n",
       "Metacrilato                                    0.0   0.0   1.0   0.0   0.0   \n",
       "La flauta de Hamelin                           0.0   0.0   0.0   0.0   0.0   \n",
       "2000 Clavos                                    0.0   0.0   0.0   0.0   0.0   \n",
       "...                                            ...   ...   ...   ...   ...   \n",
       "Need4Speed - Fumado y Hambriento               0.0   0.0   0.0   0.0   0.0   \n",
       "HOODS HOTTEST                                  0.0   0.0   0.0   0.0   0.0   \n",
       "somehow she’s still here (feat. James Blake)   0.0   0.0   0.0   0.0   0.0   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)    0.0   0.0   0.0   0.0   0.0   \n",
       "je suis                                        0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "                                              w294  w295  w296  \\\n",
       "Excesos                                        0.0   0.0   0.0   \n",
       "Calavera no chilla                             0.0   0.0   0.0   \n",
       "Metacrilato                                    0.0   0.0   0.0   \n",
       "La flauta de Hamelin                           0.0   0.0   0.0   \n",
       "2000 Clavos                                    0.0   0.0   0.0   \n",
       "...                                            ...   ...   ...   \n",
       "Need4Speed - Fumado y Hambriento               0.0   0.0   1.0   \n",
       "HOODS HOTTEST                                  0.0   0.0   1.0   \n",
       "somehow she’s still here (feat. James Blake)   0.0   0.0   1.0   \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)    0.0   0.0   1.0   \n",
       "je suis                                        0.0   0.0   2.0   \n",
       "\n",
       "                                              first_listened  last_listened  \n",
       "Excesos                                                  0.0            1.0  \n",
       "Calavera no chilla                                       0.0          158.0  \n",
       "Metacrilato                                              0.0          292.0  \n",
       "La flauta de Hamelin                                     0.0           38.0  \n",
       "2000 Clavos                                              0.0            1.0  \n",
       "...                                                      ...            ...  \n",
       "Need4Speed - Fumado y Hambriento                       296.0          297.0  \n",
       "HOODS HOTTEST                                          296.0          297.0  \n",
       "somehow she’s still here (feat. James Blake)           296.0          297.0  \n",
       "WHY AM I STILL IN LA (feat. Shlohmo & D33J)            296.0          297.0  \n",
       "je suis                                                296.0          297.0  \n",
       "\n",
       "[14082 rows x 299 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6dcd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_df['streak_list'] = np.nan\n",
    "#num_df.loc['RAPSTAR','streak_list'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5dc7fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "stream = 0\n",
    "start = int(num_df.loc[stream_list[stream],'first_listened'])\n",
    "end = int(num_df.loc[stream_list[stream],'last_listened'])\n",
    "num_df.loc[stream_list[stream], num_df.columns[start:end+1]].plot(kind = 'bar', figsize=(9, 8))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a3abe26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(num_df.columns[:-2], num_df.loc[stream_list[0], num_df.columns[:-2]])\n",
    "plt.bar(num_df.columns[:-2], num_df.loc[stream_list[1], num_df.columns[:-2]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2434f087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03062dd21314c268451be3565f0f9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in track(stream_list, description='painting'):\n",
    "    plt.bar(num_df.columns[:-2], num_df.loc[i, num_df.columns[:-2]])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6d36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 0\n",
    "l = 3\n",
    "for i in stream_list[f:l]:\n",
    "    plt.bar(num_df.columns[:-2], num_df.loc[i, num_df.columns[:-2]], label = i)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dfb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All Splitedstart = 0\n",
    "end = 4\n",
    "\n",
    "fig, axs = plt.subplots(4,1, figsize=(16, 15), facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "for ax, i in zip(axs.ravel(), stream_list[start:end]):\n",
    "    ax.bar(num_df.columns[:-2], num_df.loc[i, num_df.columns[:-2]], label = i)\n",
    "    ax.set_title(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3ba9d3",
   "metadata": {},
   "source": [
    "# <span style='background :yellow' > FIN </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34452a3e",
   "metadata": {},
   "source": [
    "# <span style='background :yellow' > Extraer Caracteristicas Manuales </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a2a60",
   "metadata": {},
   "source": [
    "#### <span style='background :yellow' > Create Stream Class?? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f579636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5fd8235",
   "metadata": {},
   "source": [
    "#### <span style='background :yellow' > ------------------------------------ </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf30181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacar las rachas\n",
    "# Primero convertimos la lista en una lista de rachas\n",
    "\n",
    "def streaks_to_list(s_l):\n",
    "    streaks_l = []\n",
    "    s_streak_l = []\n",
    "    s_aux_l = []\n",
    "    flag = 0\n",
    "    \n",
    "    for s in s_l:\n",
    "        # Next Song\n",
    "        for w in s:\n",
    "            # First iteration over a song\n",
    "            if (len(s_aux_l) == 0 and flag == 0):\n",
    "                # Start Listening the Song\n",
    "                if (w != 0):\n",
    "                    s_aux_l.append(w)\n",
    "                    flag = 1\n",
    "                    \n",
    "                # Start Without listening the Song\n",
    "                elif(w == 0):\n",
    "                    s_aux_l.append(w)\n",
    "                    flag = 2\n",
    "            \n",
    "            # Already on a Streak\n",
    "            else:\n",
    "                # Continue Streak\n",
    "                # Continue listening during next week\n",
    "                if(w != 0 and flag == 1):\n",
    "                    s_aux_l.append(w)\n",
    "                    flag = 1\n",
    "                    \n",
    "                # Continue without listening during next week\n",
    "                elif(w == 0 and flag == 2):\n",
    "                    s_aux_l.append(w)\n",
    "                    flag = 2\n",
    "                    \n",
    "                # Change\n",
    "                # Change from Stop to listen\n",
    "                elif(w != 0 and flag == 2):\n",
    "                    s_streak_l.append(s_aux_l)\n",
    "                    s_aux_l = []\n",
    "                    s_aux_l.append(w)\n",
    "                    flag = 1\n",
    "                    \n",
    "                # Change from listen to stop\n",
    "                elif(w == 0 and flag == 1):\n",
    "                    s_streak_l.append(s_aux_l)\n",
    "                    s_aux_l = []\n",
    "                    s_aux_l.append(w)\n",
    "                    flag = 2\n",
    "                \n",
    "                \n",
    "        # Song Last Iteration\n",
    "        s_streak_l.append(s_aux_l)\n",
    "        s_aux_l = []\n",
    "        \n",
    "        # Add song to streaks List\n",
    "        streaks_l.append(s_streak_l)\n",
    "        s_streak_l = []\n",
    "        flag = 0\n",
    "            \n",
    "    return streaks_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bada6ea",
   "metadata": {},
   "source": [
    "#### Check Rachas Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer comprobación todas valen 70\n",
    "n_streak_stream = streaks_to_list(num_streamed)\n",
    "print(len(n_streak_stream))\n",
    "print(len(n_streak_stream[0]))\n",
    "week_num = 0\n",
    "for a in n_streak_stream[0]:\n",
    "    week_num = week_num + len(a)\n",
    "print(week_num)\n",
    "print('\\n')\n",
    "print(len(n_streak_stream[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad23456",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccc6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streak_stream[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6d926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4583f218",
   "metadata": {},
   "source": [
    "#### Ini\n",
    "-streak_length \n",
    "\n",
    "-positive_streaks \n",
    "\n",
    "-ix_positive_streaks\n",
    "\n",
    "-negative_streaks \n",
    "\n",
    "-ix_negative_streaks\n",
    "\n",
    "-start_or_end \n",
    "\n",
    "#### Stats\n",
    "###### Max\n",
    "-max_listened\n",
    "\n",
    "-ix_max_listened\n",
    "\n",
    "###### Lenght\n",
    "-longest_streak\n",
    "\n",
    "-ix_longest_streak\n",
    "\n",
    "###### Biggest\n",
    "-max_value_streak\n",
    "\n",
    "-ix_max_value_streak\n",
    "\n",
    "###### Empty Length\n",
    "-longest_empty_streak\n",
    "\n",
    "-ix_longest_empty_streak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d596ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_streak_stream[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde07461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_streak(streaks_list):\n",
    "    (streak_length, positive_streaks, ix_positive_streaks, \n",
    "     negative_streaks, ix_negative_streaks, start_or_end) = ini_count_streaks(streaks_list)\n",
    "    \n",
    "    (max_listened, ix_max_listened, longest_streak, value_longest_streak, ix_longest_streak, \n",
    "     max_value_streak, value_max_value_streak, ix_max_value_streak) = positive_stats_streaks(streaks_list, ix_positive_streaks)\n",
    "    \n",
    "    value_longest_empty_streak, ix_longest_empty_streak = negative_stats_streaks(streaks_list, ix_negative_streaks)\n",
    "    \n",
    "    return (streak_length, positive_streaks, ix_positive_streaks, \n",
    "            negative_streaks, ix_negative_streaks, start_or_end, \n",
    "            max_listened, ix_max_listened, longest_streak, value_longest_streak, ix_longest_streak, \n",
    "            max_value_streak, value_max_value_streak, ix_max_value_streak, \n",
    "            value_longest_empty_streak, ix_longest_empty_streak)\n",
    "    \n",
    "def ini_count_streaks(streaks_list):\n",
    "    streak_length = len(streaks_list)\n",
    "    positive_streaks = 0\n",
    "    negative_streaks = 0\n",
    "    ix_positive_streaks = []\n",
    "    ix_negative_streaks = []\n",
    "    start_or_end = ''\n",
    "    \n",
    "    i = 0\n",
    "    for s in streaks_list:\n",
    "        if i == 0 and s[0] == 0:\n",
    "            start_or_end = 'end'\n",
    "            negative_streaks = negative_streaks+1\n",
    "            ix_negative_streaks.append(i)\n",
    "            \n",
    "        elif i == 0 and s[0] != 0:\n",
    "            start_or_end = 'start'\n",
    "            positive_streaks = positive_streaks+1\n",
    "            ix_positive_streaks.append(i)\n",
    "            \n",
    "        elif s[0] == 0:\n",
    "            negative_streaks = negative_streaks+1\n",
    "            ix_negative_streaks.append(i)\n",
    "            \n",
    "        elif s[0] != 0:\n",
    "            positive_streaks = positive_streaks+1\n",
    "            ix_positive_streaks.append(i)\n",
    "            \n",
    "        i = i+1\n",
    "    \n",
    "    return streak_length, positive_streaks, ix_positive_streaks, negative_streaks, ix_negative_streaks, start_or_end\n",
    "\n",
    "\n",
    "\n",
    "def positive_stats_streaks(streaks_list, ix_positive_streaks):\n",
    "    max_listened = 0\n",
    "    ix_max_listened = 0\n",
    "\n",
    "    longest_streak = []\n",
    "    value_longest_streak = 0\n",
    "    ix_longest_streak = 0\n",
    "    \n",
    "    max_value_streak = []\n",
    "    value_max_value_streak = 0\n",
    "    ix_max_value_streak = 0\n",
    "\n",
    "    i = 0\n",
    "    for p in ix_positive_streaks:\n",
    "        if(max_listened < max(streaks_list[p])):\n",
    "            max_listened = max(streaks_list[p])\n",
    "            ix_max_listened = i\n",
    "            \n",
    "        if(value_longest_streak < len(streaks_list[p])):\n",
    "            value_longest_streak = len(streaks_list[p])\n",
    "            longest_streak = streaks_list[p]\n",
    "            ix_longest_streak = i\n",
    "        \n",
    "        if(value_max_value_streak < sum(streaks_list[p])):\n",
    "            value_max_value_streak = sum(streaks_list[p])\n",
    "            max_value_streak = streaks_list[p]\n",
    "            ix_max_value_streak = i\n",
    "        \n",
    "        i = i+1        \n",
    "    \n",
    "    return (max_listened, ix_max_listened, longest_streak, value_longest_streak, ix_longest_streak, \n",
    "            max_value_streak, value_max_value_streak, ix_max_value_streak)\n",
    "        \n",
    "def negative_stats_streaks(streaks_list, ix_negative_streaks):\n",
    "    value_longest_empty_streak = 0\n",
    "    ix_longest_empty_streak = 0\n",
    "\n",
    "    i = 0\n",
    "    for n in ix_negative_streaks:\n",
    "        if(value_longest_empty_streak < len(streaks_list[n])):\n",
    "            value_longest_empty_streak = len(streaks_list[n])\n",
    "            ix_longest_empty_streak = i\n",
    "        \n",
    "        i = i+1\n",
    "    \n",
    "    return value_longest_empty_streak, ix_longest_empty_streak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f81f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ini Lists\n",
    "streak_length = []\n",
    "positive_streaks = []\n",
    "ix_positive_streaks = []\n",
    "negative_streaks = []\n",
    "ix_negative_streaks = []\n",
    "start_or_end = [] \n",
    "\n",
    "# Stats Lists\n",
    "# Postive\n",
    "max_listened = []\n",
    "ix_max_listened = []\n",
    "\n",
    "longest_streak = []\n",
    "value_longest_streak = []\n",
    "ix_longest_streak = []\n",
    "\n",
    "max_value_streak = []\n",
    "value_max_value_streak = []\n",
    "ix_max_value_streak = []\n",
    "\n",
    "# Negative\n",
    "value_longest_empty_streak = []\n",
    "ix_longest_empty_streak = []\n",
    "\n",
    "aux = []\n",
    "\n",
    "for s in track(n_streak_stream, description='Extracting Streaks Stats'):\n",
    "    aux = define_streak(s)\n",
    "    # ini - from 0 to 5 == 6\n",
    "    # pos - from 6 to 13 == 8\n",
    "    # neg - from 14 to 15 == 2\n",
    "    # Total = 16 \n",
    "    \n",
    "    streak_length.append(aux[0])\n",
    "    positive_streaks.append(aux[1])\n",
    "    ix_positive_streaks.append(aux[2])\n",
    "    negative_streaks.append(aux[3])\n",
    "    ix_negative_streaks.append(aux[4])\n",
    "    start_or_end.append(aux[5])\n",
    "\n",
    "    max_listened.append(aux[6])\n",
    "    ix_max_listened.append(aux[7])\n",
    "    longest_streak.append(aux[8])\n",
    "    value_longest_streak.append(aux[9])\n",
    "    ix_longest_streak.append(aux[10])\n",
    "    max_value_streak.append(aux[11])\n",
    "    value_max_value_streak.append(aux[12])\n",
    "    ix_max_value_streak.append(aux[13])\n",
    "    \n",
    "    value_longest_empty_streak.append(aux[14])\n",
    "    ix_longest_empty_streak.append(aux[15])\n",
    "    aux = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb0f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_max_value_streak[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_streak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eec4b3",
   "metadata": {},
   "source": [
    "### Flatten to make a histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8473a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "flat_longest_streak = [e for s in longest_streak for e in s]\n",
    "flat_longest_streak\n",
    "\n",
    "counts = Counter(flat_longest_streak)\n",
    "print(counts)\n",
    "\n",
    "plt.bar(counts.keys(), counts.values(), color='b')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c8f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts.values()) - (counts[1] + counts[2] + counts[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc93c75",
   "metadata": {},
   "source": [
    "#### <span style='background :yellow' > Media de cuanto es la mayor racha de escucha </span>\n",
    "#### <span style='background :yellow' > Media de cuanto es la primera racha de escucha </span>\n",
    "#### <span style='background :yellow' > Canciones con valor solo una semana de escucha se pueden eliminar </span>\n",
    "#### <span style='background :yellow' > Tratar Rachas negativas FIN (es decir no se han vuelto a escuchar hasta la fecha) </span>\n",
    "#### <span style='background :yellow' > Tratar Rachas negativas START (aun no se han descubierto) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0374903a",
   "metadata": {},
   "source": [
    "### Outlayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec48d97",
   "metadata": {},
   "source": [
    "#### Z-Score Vs IQR -- We making IQR but bibliograpghy pls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(data, low_p = 2.5, high_p = 97.5):\n",
    "    q1, q3 = np.percentile(data, [low_p, high_p])\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((data > upper_bound) | (data < lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379422de",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices = detect_outliers_iqr(flat_longest_streak, 25, 75)\n",
    "print(outlier_indices)\n",
    "print(len(outlier_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec449ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices = detect_outliers_iqr(flat_longest_streak)\n",
    "print(outlier_indices)\n",
    "print(len(outlier_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6200202",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_p = []\n",
    "for i in outlier_indices[0]:\n",
    "    outs_p.append(flat_longest_streak[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66469ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_p_count = Counter(outs_p)\n",
    "print(outs_p_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d81f5",
   "metadata": {},
   "source": [
    "#### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_z_score(data):\n",
    "    threshold = 3\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    z_scores = [(y - mean) / std for y in data]\n",
    "    return np.where(np.abs(z_scores) > threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cf565",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_indices = detect_outliers_z_score(flat_longest_streak)\n",
    "print(len(outlier_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cfce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_z = []\n",
    "for i in outlier_indices[0]:\n",
    "    outs_z.append(flat_longest_streak[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cec69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_z_count = Counter(outs_z)\n",
    "print(outs_z_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eedadf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f351f4c1",
   "metadata": {},
   "source": [
    "# Resulting Plot Removing Outlayers and 1s - even 2s??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cae952",
   "metadata": {},
   "source": [
    "#### We want to train with all information possible, like 1, 2 and 3 are all the 25-75 percentil, the best is to remove them 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''p75 = np.percentile(numbers, 75)\n",
    "p75\n",
    "\n",
    "per75 = Counter([x for x in numbers if x >= p75])\n",
    "print(per75)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686d784",
   "metadata": {},
   "source": [
    "### Full Remove Most repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#longest_streak\n",
    "#flat_longest_streak\n",
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aux dictionary\n",
    "full_remove = counts.copy()\n",
    "\n",
    "# Remove 75p\n",
    "full_remove.pop(1)\n",
    "full_remove.pop(2)\n",
    "full_remove.pop(3)\n",
    "\n",
    "# Remove outlayers\n",
    "for i in outs_p_count:\n",
    "    full_remove.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a779d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_remove)\n",
    "\n",
    "plt.bar(full_remove.keys(), full_remove.values(), color='b')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(full_remove.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a66f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_75 = 0\n",
    "flag_0 = 0\n",
    "\n",
    "full_remove_list = []\n",
    "\n",
    "for f in flat_longest_streak:\n",
    "    # 75% of data Condition\n",
    "    for i in [1,2,3]:\n",
    "        if f == i:\n",
    "            flag_75 = 1\n",
    "            \n",
    "    # Outlayer Condition\n",
    "    for outlayer in outs_p_count:\n",
    "        if f == outlayer:\n",
    "            flag_0 = 1\n",
    "            \n",
    "    if flag_75 == 0 and flag_0 == 0:\n",
    "        full_remove_list.append(f)\n",
    "        \n",
    "    flag_75 = 0\n",
    "    flag_0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5353310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(full_remove_list))\n",
    "magic_number = round(np.mean(full_remove_list))\n",
    "magic_number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1de74",
   "metadata": {},
   "source": [
    "# <span style='background :yellow' > Try different Strategies to compare how the predictions are done </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aeb8d8",
   "metadata": {},
   "source": [
    "This proces will all data, only removing +75% percentil, excludes the highest streaks, and the ending result is = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
