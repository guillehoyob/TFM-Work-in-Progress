{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39396163",
   "metadata": {},
   "source": [
    "# Baseline Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f0d52",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/multivariate-time-series-forecasting-using-random-forest-2372f3ecbad1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adebbb6",
   "metadata": {},
   "source": [
    "# <span style='background :khaki' > Install & Importa Libraries </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae51247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.19 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from seaborn) (1.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from seaborn) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from seaborn) (1.23.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.38.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (1.9.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from lightgbm) (1.23.4)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: dtale in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2021.10.8)\n",
      "Requirement already satisfied: future>=0.14.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.18.3)\n",
      "Requirement already satisfied: openpyxl!=3.2.0b1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (3.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.5.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (4.11.2)\n",
      "Requirement already satisfied: Flask-Compress in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.13)\n",
      "Requirement already satisfied: dash-daq in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.5.0)\n",
      "Requirement already satisfied: dash-colorscales in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.0.4)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.27.1)\n",
      "Requirement already satisfied: kaleido in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.2.1)\n",
      "Requirement already satisfied: dash-bootstrap-components<=1.3.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.3.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.12.1)\n",
      "Requirement already satisfied: Flask in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.2.3)\n",
      "Requirement already satisfied: missingno<=0.4.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.4.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (3.0)\n",
      "Requirement already satisfied: xlrd in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.0.1)\n",
      "Requirement already satisfied: itsdangerous in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.1.2)\n",
      "Requirement already satisfied: strsimpy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.2.1)\n",
      "Requirement already satisfied: xarray in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2023.2.0)\n",
      "Requirement already satisfied: lz4 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (4.3.2)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.13.5)\n",
      "Requirement already satisfied: dash>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (2.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.1.3)\n",
      "Requirement already satisfied: six in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.16.0)\n",
      "Requirement already satisfied: flask-ngrok in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.0.25)\n",
      "Requirement already satisfied: matplotlib==3.6.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (3.6.0)\n",
      "Requirement already satisfied: cycler in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.11.0)\n",
      "Requirement already satisfied: squarify in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (0.4.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.9.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (1.23.4)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dtale) (5.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (3.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from matplotlib==3.6.0->dtale) (21.3)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dash>=2.0.0->dtale) (5.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dash>=2.0.0->dtale) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from dash>=2.0.0->dtale) (2.0.0)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=3.6.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (4.8.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask->dtale) (2.2.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from plotly>=5.0.0->dtale) (8.2.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from beautifulsoup4->dtale) (2.4)\n",
      "Requirement already satisfied: brotli in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Flask-Compress->dtale) (1.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas->dtale) (2022.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from requests->dtale) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from requests->dtale) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from requests->dtale) (1.26.8)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn->dtale) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn->dtale) (3.1.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from statsmodels->dtale) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from click>=8.0->Flask->dtale) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from importlib-metadata>=3.6.0->Flask->dtale) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Jinja2>=3.0->Flask->dtale) (2.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numba>=0.53 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (0.56.4)\n",
      "Requirement already satisfied: scikit-learn<1.3.0,>=0.24.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.1.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.9.3)\n",
      "Requirement already satisfied: pandas<1.6.0,>=1.1.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.5.1)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.2.13)\n",
      "Requirement already satisfied: numpy<1.25,>=1.21.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sktime) (1.23.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from deprecated>=1.2.13->sktime) (1.15.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.53->sktime) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.53->sktime) (58.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas<1.6.0,>=1.1.0->sktime) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas<1.6.0,>=1.1.0->sktime) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn<1.3.0,>=0.24.0->sktime) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas<1.6.0,>=1.1.0->sktime) (1.16.0)\n",
      "Requirement already satisfied: sklego in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-lego in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from sklego) (0.6.14)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (0.5.3)\n",
      "Requirement already satisfied: Deprecated>=1.2.6 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.2.13)\n",
      "Requirement already satisfied: umap-learn>=0.4.6 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (0.5.3)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.1.3)\n",
      "Requirement already satisfied: autograd>=1.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-lego->sklego) (1.5)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from autograd>=1.2->scikit-lego->sklego) (0.18.3)\n",
      "Requirement already satisfied: numpy>=1.12 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from autograd>=1.2->scikit-lego->sklego) (1.23.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from Deprecated>=1.2.6->scikit-lego->sklego) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego->sklego) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from pandas>=1.1.5->scikit-lego->sklego) (2022.6)\n",
      "Requirement already satisfied: six in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from patsy>=0.5.1->scikit-lego->sklego) (1.16.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.24.1->scikit-lego->sklego) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.24.1->scikit-lego->sklego) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from scikit-learn>=0.24.1->scikit-lego->sklego) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from umap-learn>=0.4.6->scikit-lego->sklego) (4.63.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from umap-learn>=0.4.6->scikit-lego->sklego) (0.5.8)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from umap-learn>=0.4.6->scikit-lego->sklego) (0.56.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego->sklego) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego->sklego) (0.39.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (from tqdm->umap-learn>=0.4.6->scikit-lego->sklego) (0.4.4)\n",
      "Requirement already satisfied: pip in c:\\users\\ghoyo\\miniconda3\\lib\\site-packages (23.0.1)\n"
     ]
    }
   ],
   "source": [
    "### ***Enviroment Preparation***\n",
    "# Install Pandas\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install lightgbm\n",
    "\n",
    "!pip install dtale\n",
    "\n",
    "!pip install sktime\n",
    "!pip install sklego\n",
    "\n",
    "#!pip install skforecast\n",
    "\n",
    "# Update pip -- WARNING Resolution\n",
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa0a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ***Imports***\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import dtale\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import time\n",
    "# Current Location.. !cd\n",
    "#C:\\Users\\ghoyo\\Desktop\\TFM\\Nuevo\\Proyect\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "data = r\"C:\\Users\\ghoyo\\Desktop\\TFM4\\Project\\GeneratedDfs\\dayly_rests_type.json\"\n",
    "\n",
    "# Full Time\n",
    "start_full_infi = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f00ba81",
   "metadata": {},
   "source": [
    "#### <span style=\"background:skyblue\"> Load Data <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79edec2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11504, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6818f0",
   "metadata": {},
   "source": [
    "#### <span style=\"background:skyblue\"> Little Analysis <span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f78a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 11504 entries, 2017-04-04 14:06:56 to 2022-11-24 22:04:22\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype\n",
      "---  ------              --------------  -----\n",
      " 0   rest_type           11504 non-null  int64\n",
      " 1   n_streams_listened  11504 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 269.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "445a5ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rest_type</th>\n",
       "      <td>11504.0</td>\n",
       "      <td>2.459840</td>\n",
       "      <td>1.685460</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_streams_listened</th>\n",
       "      <td>11504.0</td>\n",
       "      <td>7.129781</td>\n",
       "      <td>8.876177</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count      mean       std  min  25%  50%  75%    max\n",
       "rest_type           11504.0  2.459840  1.685460  0.0  1.0  2.0  4.0    6.0\n",
       "n_streams_listened  11504.0  7.129781  8.876177  1.0  2.0  5.0  9.0  191.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20027aa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest_type</th>\n",
       "      <th>n_streams_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-04 14:06:56</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-04 14:55:10</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-04 16:28:27</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-04 17:28:27</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rest_type  n_streams_listened\n",
       "2017-04-04 14:06:56          1                   2\n",
       "2017-04-04 14:55:10          1                   9\n",
       "2017-04-04 16:28:27          2                   7\n",
       "2017-04-04 17:28:27          0                  18"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10507854",
   "metadata": {},
   "source": [
    "# <span style='background :khaki' > Random Forest Predictions </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20a7286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming number of predicted rest for next day is = 6\n",
    "n_rests = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737080c2",
   "metadata": {},
   "source": [
    "#### <span style=\"background:violet\"> Functions <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4828749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits, numb):\n",
    "        self.n_splits = n_splits\n",
    "        self.numb = numb\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = stop-self.numb\n",
    "            yield indices[start: mid], indices[mid + margin: stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3919a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_feature_importance_class(df, target, split=7, n_s=100, plot = 0, r = 0, sort = 0):\n",
    "    # Data\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    \n",
    "    # Split\n",
    "    X_train, X_test = X.iloc[:-split,:], X.iloc[-split:,:]\n",
    "    y_train, y_test = y.iloc[:-split], y.iloc[-split:]\n",
    "    \n",
    "    # Create - Train - Predict\n",
    "    model = RandomForestClassifier(n_estimators=n_s)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Evaluation Methods - accuracy, precision, recall & F1-score\n",
    "    accuracy = np.round(accuracy_score(y_test, predictions), 3)    \n",
    "    precision = np.round(precision_score(y_test, predictions, average='weighted'), 3)    \n",
    "    recall = np.round(recall_score(y_test, predictions, average='weighted'), 3)    \n",
    "    f1 = np.round(f1_score(y_test, predictions, average='weighted'), 3)    \n",
    "\n",
    "    #print('Accuracy:', accuracy)\n",
    "    #print('Precision:', precision)\n",
    "    #print('Recall:', recall)\n",
    "    #print('F1-score:', f1)\n",
    "    \n",
    "    # Plot Real Vs Prediction\n",
    "    if plot == 0 or plot == 1:\n",
    "        fig = plt.figure(figsize=(6,3))\n",
    "        plt.title(f' {target}: Random Forest Real vs Prediction - Accuracy {accuracy}', fontsize=20)\n",
    "        plt.plot(y_test, color='red')\n",
    "        plt.plot(pd.Series(predictions, index=y_test.index), color='green')\n",
    "        plt.xlabel('Days', fontsize=12)\n",
    "        plt.ylabel('Target variable', fontsize=12)\n",
    "        plt.legend(labels=['Real', 'Prediction'], fontsize=12)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    \n",
    "    # Dataframe with Importance of each feature\n",
    "    if sort == 0:\n",
    "        df_importances = pd.DataFrame({\n",
    "            'feature': df.drop(columns = target).columns,\n",
    "            'importance': model.feature_importances_}\n",
    "        ).sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    if sort == 1:\n",
    "        df_importances = pd.DataFrame({\n",
    "            'feature': df.drop(columns = target).columns,\n",
    "            'importance': model.feature_importances_}\n",
    "        )\n",
    "    \n",
    "    # Plot Features Importance\n",
    "    if plot == 0 or plot == 2:\n",
    "        plt.figure(figsize=(12,8))\n",
    "        plt.title('Variable Importances', fontsize=12)\n",
    "        sns.barplot(x=df_importances.importance, y=df_importances.feature, orient='h')\n",
    "        plt.show()\n",
    "        \n",
    "    #  Print Importances\n",
    "    #print('Accuracy: ', accuracy)\n",
    "    #print(df_importances.sort_values(by='importance'), '\\n')\n",
    "    \n",
    "    if r == 1:\n",
    "        return accuracy, precision, recall, f1, df_importances\n",
    "    \n",
    "    return accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c127bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_classification_cv(df, target, cv = 2, cv_split=5, n_s=100, test_size=0.3):\n",
    "    # Results\n",
    "    c_predict = []\n",
    "    c_acc = []\n",
    "    c_pre = []\n",
    "    c_rec = []\n",
    "    c_f1 = []\n",
    "    \n",
    "    # Data\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "    \n",
    "    # CV Method\n",
    "    if(cv == 1):\n",
    "        tscv = TimeSeriesSplit(max_train_size=None, n_splits=cv_split, test_size=test_size)\n",
    "    elif(cv == 2):\n",
    "        tscv = BlockingTimeSeriesSplit(n_splits = cv_split, numb = test_size)\n",
    "    \n",
    "    # Split CV Data\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        pre = []\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=n_s)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        c_predict.append(y_pred)\n",
    "        c_acc.append(accuracy_score(y_test, y_pred))\n",
    "        c_pre.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        c_rec.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        c_f1.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    accuracy = np.mean(c_acc)\n",
    "    precision = np.mean(c_pre)\n",
    "    recall = np.mean(c_rec)\n",
    "    f1 = np.mean(c_f1)\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fbcbd",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > Global Variables </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abf7d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_split = 14\n",
    "n_sims = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961b57e",
   "metadata": {},
   "source": [
    "### <span style=\"background:lightGreen\"> Prediction BASE <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e7acf",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > BASE </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56d51d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20.2 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full = time.time()\n",
    "\n",
    "b_acc = []\n",
    "b_pre = []\n",
    "b_rec = []\n",
    "b_f1 = []\n",
    "b_vi = []\n",
    "\n",
    "b_sim_acc = []\n",
    "b_sim_pre = []\n",
    "b_sim_rec = []\n",
    "b_sim_f1 = []\n",
    "b_sim_vi = []\n",
    "    \n",
    "target = df.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc, pre, rec, f1, vi = tree_feature_importance_class(df, target, split=n_rests, plot = 3, r = 1)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    b_sim_acc.append(acc)\n",
    "    b_sim_pre.append(pre)\n",
    "    b_sim_rec.append(rec)\n",
    "    b_sim_f1.append(f1)\n",
    "    b_sim_vi.append(vi)\n",
    "        \n",
    "        \n",
    "mean_sim_vi = pd.DataFrame(columns = ['feature', 'importance'])\n",
    "\n",
    "# Loop to make variable importance simulation mean\n",
    "for i,col in zip(range(b_sim_vi[0].shape[0]), b_sim_vi[0]['feature']):\n",
    "    aux = []\n",
    "    \n",
    "    for j in range(n_sims):\n",
    "        aux.append(b_sim_vi[j]['importance'][i])\n",
    "    \n",
    "    mean_sim_vi.loc[i, 'feature'] = col\n",
    "    mean_sim_vi.loc[i, 'importance'] = np.mean(aux)\n",
    "\n",
    "#print('\\n Mean Variable Importance LAGS DATAFRAMES \\n')\n",
    "#mean_sim_vi.head()\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "b_acc.append(np.mean(b_sim_acc))\n",
    "b_pre.append(np.mean(b_sim_pre))\n",
    "b_rec.append(np.mean(b_sim_rec))\n",
    "b_f1.append(np.mean(b_sim_f1))\n",
    "b_vi.append(mean_sim_vi)\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc)\n",
    "#print(lag_pre)\n",
    "#print(lag_rec)\n",
    "#print(lag_f1)\n",
    "#print(lag_vi)\n",
    "\n",
    "end_full = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "689550af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.020040000000000002]\n",
      "[0.09996]\n",
      "[0.020040000000000002]\n",
      "[0.03336]\n"
     ]
    }
   ],
   "source": [
    "print(b_acc)\n",
    "print(b_pre)\n",
    "print(b_rec)\n",
    "print(b_f1)\n",
    "#print(lag_vi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e6da8",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > CV </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc53517",
   "metadata": {},
   "source": [
    "TSCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b2626c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 16s\n",
      "Wall time: 5min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_tscv = time.time()\n",
    "\n",
    "bl_acc_tscv = []\n",
    "bl_pre_tscv = []\n",
    "bl_rec_tscv = []\n",
    "bl_f1_tscv = []\n",
    "bl_vi_tscv = []\n",
    "\n",
    "bl_sim_acc_tscv = []\n",
    "bl_sim_pre_tscv = []\n",
    "bl_sim_rec_tscv = []\n",
    "bl_sim_f1_tscv = []\n",
    "bl_sim_vi_tscv = []\n",
    "    \n",
    "target = df.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    b_acc_tscv, b_pre_tscv, b_rec_tscv, b_f1_tscv = tree_classification_cv(df, target, cv = 1, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    bl_sim_acc_tscv.append(b_acc_tscv)\n",
    "    bl_sim_pre_tscv.append(b_pre_tscv)\n",
    "    bl_sim_rec_tscv.append(b_rec_tscv)\n",
    "    bl_sim_f1_tscv.append(b_f1_tscv)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "bl_acc_tscv.append(np.mean(bl_sim_acc_tscv))\n",
    "bl_pre_tscv.append(np.mean(bl_sim_pre_tscv))\n",
    "bl_rec_tscv.append(np.mean(bl_sim_rec_tscv))\n",
    "bl_f1_tscv.append(np.mean(bl_sim_f1_tscv))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(b_acc_tscv)\n",
    "#print(b_pre_tscv)\n",
    "#print(b_rec_tscv)\n",
    "#print(b_f1_tscv)\n",
    "\n",
    "end_full_tscv = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c2deac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.131\n",
      "0.037698412698412696\n",
      "0.13095238095238096\n",
      "0.05668934240362812\n"
     ]
    }
   ],
   "source": [
    "print(np.round(b_acc_tscv,3))\n",
    "print(b_pre_tscv)\n",
    "print(b_rec_tscv)\n",
    "print(b_f1_tscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e4d667",
   "metadata": {},
   "source": [
    "BCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f1651ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5min 25s\n",
      "Wall time: 5min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_bcv = time.time()\n",
    "\n",
    "bl_acc_bcv = []\n",
    "bl_pre_bcv = []\n",
    "bl_rec_bcv = []\n",
    "bl_f1_bcv = []\n",
    "bl_vi_bcv = []\n",
    "\n",
    "bl_sim_acc_bcv = []\n",
    "bl_sim_pre_bcv = []\n",
    "bl_sim_rec_bcv = []\n",
    "bl_sim_f1_bcv = []\n",
    "bl_sim_vi_bcv = []\n",
    "    \n",
    "target = df.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    b_acc_bcv, b_pre_bcv, b_rec_bcv, b_f1_bcv = tree_classification_cv(df, target, cv = 1, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    bl_sim_acc_bcv.append(b_acc_bcv)\n",
    "    bl_sim_pre_bcv.append(b_pre_bcv)\n",
    "    bl_sim_rec_bcv.append(b_rec_bcv)\n",
    "    bl_sim_f1_bcv.append(b_f1_bcv)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "bl_acc_bcv.append(np.mean(bl_sim_acc_bcv))\n",
    "bl_pre_bcv.append(np.mean(bl_sim_pre_bcv))\n",
    "bl_rec_bcv.append(np.mean(bl_sim_rec_bcv))\n",
    "bl_f1_bcv.append(np.mean(bl_sim_f1_bcv))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(b_acc_bcv)\n",
    "#print(b_pre_bcv)\n",
    "#print(b_rec_bcv)\n",
    "#print(b_f1_bcv)\n",
    "\n",
    "end_full_bcv = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6d6c59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.127]\n",
      "[0.05411640211640211]\n",
      "[0.12730158730158728]\n",
      "[0.0602358276643991]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(bl_acc_bcv,3))\n",
    "print(bl_pre_bcv)\n",
    "print(bl_rec_bcv)\n",
    "print(bl_f1_bcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce348c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b8b478d",
   "metadata": {},
   "source": [
    "### <span style=\"background:lightGreen\"> Predictiones <span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea93bf",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > Generate Lags and Select a Best number of Lags </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd6a7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lagged_dfs(df, target_col, num_lags, start):\n",
    "    lagged_dfs = []\n",
    "    for i in range(0, start):\n",
    "        if len(lagged_dfs) == 0:\n",
    "            lagged_df = df.copy()\n",
    "        else:\n",
    "            lagged_df = lagged_dfs[-1].copy()\n",
    "        lagged_df[target_col + '_lag_' + str(i+1)] = df[target_col].shift(i+1)\n",
    "        lagged_dfs.append(lagged_df)\n",
    "    for i in range(start, start + num_lags):\n",
    "        if len(lagged_dfs) == 0:\n",
    "            lagged_df = df.copy()\n",
    "        else:\n",
    "            lagged_df = lagged_dfs[-1].copy()\n",
    "        lagged_df[target_col + '_lag_' + str(i+1)] = df[target_col].shift(i+1)\n",
    "        lagged_dfs.append(lagged_df)\n",
    "    for d in lagged_dfs:\n",
    "        d.dropna(inplace=True)\n",
    "        \n",
    "    return lagged_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b03636f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lag_df = generate_lagged_dfs(df, 'rest_type', n_rests, 8)\n",
    "for i in range(n_rests-1):\n",
    "    lag_df.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dec94545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "057d6e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rest_type</th>\n",
       "      <th>n_streams_listened</th>\n",
       "      <th>rest_type_lag_1</th>\n",
       "      <th>rest_type_lag_2</th>\n",
       "      <th>rest_type_lag_3</th>\n",
       "      <th>rest_type_lag_4</th>\n",
       "      <th>rest_type_lag_5</th>\n",
       "      <th>rest_type_lag_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-04-05 10:14:38</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05 12:07:17</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05 14:18:35</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05 17:10:01</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05 18:22:31</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-05 19:24:03</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06 05:32:24</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06 11:49:48</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06 12:46:40</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-06 17:47:23</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     rest_type  n_streams_listened  rest_type_lag_1  \\\n",
       "2017-04-05 10:14:38          2                  54              5.0   \n",
       "2017-04-05 12:07:17          2                  16              2.0   \n",
       "2017-04-05 14:18:35          2                   5              2.0   \n",
       "2017-04-05 17:10:01          2                  23              2.0   \n",
       "2017-04-05 18:22:31          1                  10              2.0   \n",
       "2017-04-05 19:24:03          1                   9              1.0   \n",
       "2017-04-06 05:32:24          5                   6              1.0   \n",
       "2017-04-06 11:49:48          4                  10              5.0   \n",
       "2017-04-06 12:46:40          0                  14              4.0   \n",
       "2017-04-06 17:47:23          4                   1              0.0   \n",
       "\n",
       "                     rest_type_lag_2  rest_type_lag_3  rest_type_lag_4  \\\n",
       "2017-04-05 10:14:38              1.0              0.0              2.0   \n",
       "2017-04-05 12:07:17              5.0              1.0              0.0   \n",
       "2017-04-05 14:18:35              2.0              5.0              1.0   \n",
       "2017-04-05 17:10:01              2.0              2.0              5.0   \n",
       "2017-04-05 18:22:31              2.0              2.0              2.0   \n",
       "2017-04-05 19:24:03              2.0              2.0              2.0   \n",
       "2017-04-06 05:32:24              1.0              2.0              2.0   \n",
       "2017-04-06 11:49:48              1.0              1.0              2.0   \n",
       "2017-04-06 12:46:40              5.0              1.0              1.0   \n",
       "2017-04-06 17:47:23              4.0              5.0              1.0   \n",
       "\n",
       "                     rest_type_lag_5  rest_type_lag_6  \n",
       "2017-04-05 10:14:38              1.0              1.0  \n",
       "2017-04-05 12:07:17              2.0              1.0  \n",
       "2017-04-05 14:18:35              0.0              2.0  \n",
       "2017-04-05 17:10:01              1.0              0.0  \n",
       "2017-04-05 18:22:31              5.0              1.0  \n",
       "2017-04-05 19:24:03              2.0              5.0  \n",
       "2017-04-06 05:32:24              2.0              2.0  \n",
       "2017-04-06 11:49:48              2.0              2.0  \n",
       "2017-04-06 12:46:40              2.0              2.0  \n",
       "2017-04-06 17:47:23              1.0              2.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_df[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4294d",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > Variables Importance </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed797e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME:  rest_type -- Last Lag ------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tree_feature_importance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree_feature_importance' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for d in lag_df:\n",
    "    print('DATAFRAME: ', d.columns[0], '-- Last Lag ------------------------------------')\n",
    "    target = d.columns[0]\n",
    "    tree_feature_importance(d, target, split=n_rests, plot = 2, r = 1, sort=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a6e87",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > Basic RF </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6cfad04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 18s\n",
      "Wall time: 19min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full = time.time()\n",
    "\n",
    "lag_acc = []\n",
    "lag_pre = []\n",
    "lag_rec = []\n",
    "lag_f1 = []\n",
    "lag_vi = []\n",
    "\n",
    "for d, r in zip(lag_df, range(n_rests)):\n",
    "    sim_acc = []\n",
    "    sim_pre = []\n",
    "    sim_rec = []\n",
    "    sim_f1 = []\n",
    "    sim_vi = []\n",
    "    \n",
    "    target = d.columns[0]\n",
    "    \n",
    "    for sim in range(n_sims):\n",
    "        #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "        acc, pre, rec, f1, vi = tree_feature_importance_class(d, target, split=n_rests, plot = 3, r = 1)\n",
    "        \n",
    "        # Save data -- SIM\n",
    "        sim_acc.append(acc)\n",
    "        sim_pre.append(pre)\n",
    "        sim_rec.append(rec)\n",
    "        sim_f1.append(f1)\n",
    "        sim_vi.append(vi)\n",
    "        \n",
    "        \n",
    "    mean_sim_vi = pd.DataFrame(columns = ['feature', 'importance'])\n",
    "\n",
    "    # Loop to make variable importance simulation mean\n",
    "    for i,col in zip(range(sim_vi[0].shape[0]), sim_vi[0]['feature']):\n",
    "        aux = []\n",
    "    \n",
    "        for j in range(n_sims):\n",
    "            aux.append(sim_vi[j]['importance'][i])\n",
    "    \n",
    "        mean_sim_vi.loc[i, 'feature'] = col\n",
    "        mean_sim_vi.loc[i, 'importance'] = np.mean(aux)\n",
    "\n",
    "    #print('\\n Mean Variable Importance LAGS DATAFRAMES \\n')\n",
    "    #mean_sim_vi.head()\n",
    "    \n",
    "    # Save Data -- LAG Loop\n",
    "    lag_acc.append(np.mean(sim_acc))\n",
    "    lag_pre.append(np.mean(sim_pre))\n",
    "    lag_rec.append(np.mean(sim_rec))\n",
    "    lag_f1.append(np.mean(sim_f1))\n",
    "    lag_vi.append(mean_sim_vi)\n",
    "    \n",
    "    # Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "    #print(lag_acc)\n",
    "    #print(lag_pre)\n",
    "    #print(lag_rec)\n",
    "    #print(lag_f1)\n",
    "    #print(lag_vi)\n",
    "\n",
    "end_full = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6549a77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full time:  1172825.243473053 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"full time: \", (end_full-start_full)* 10**3, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "980d63fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3998133333333333, 0.2888133333333333, 0.20684, 0.27110666666666666, 0.31997333333333333, 0.33996]\n",
      "[0.58636, 0.5244266666666666, 0.4521866666666667, 0.5996133333333333, 0.7196266666666666, 0.58948]\n",
      "[0.3998133333333333, 0.2888133333333333, 0.20684, 0.27110666666666666, 0.31997333333333333, 0.33996]\n",
      "[0.4728533333333333, 0.3671333333333333, 0.28134666666666663, 0.3621333333333333, 0.4237866666666667, 0.41973333333333335]\n"
     ]
    }
   ],
   "source": [
    "print(lag_acc)\n",
    "print(lag_pre)\n",
    "print(lag_rec)\n",
    "print(lag_f1)\n",
    "#print(lag_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca855f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_df[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6bf3b9",
   "metadata": {},
   "source": [
    "#### <span style='background :skyblue' > CV </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb029d",
   "metadata": {},
   "source": [
    "<span style='background :skyblue' > TSCV </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac33ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_full_tscv = time.time()\n",
    "\n",
    "lag_acc_tscv = []\n",
    "lag_pre_tscv = []\n",
    "lag_rec_tscv = []\n",
    "lag_f1_tscv = []\n",
    "lag_vi_tscv = []\n",
    "\n",
    "for d, r in zip(lag_df, range(n_rests)):\n",
    "    sim_acc_tscv = []\n",
    "    sim_pre_tscv = []\n",
    "    sim_rec_tscv = []\n",
    "    sim_f1_tscv = []\n",
    "    sim_vi_tscv = []\n",
    "    \n",
    "    target = d.columns[0]\n",
    "    \n",
    "    for sim in range(n_sims):\n",
    "        #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "        acc_tscv, pre_tscv, rec_tscv, f1_tscv = tree_classification_cv(d, target, cv = 1, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "        # Save data -- SIM\n",
    "        sim_acc_tscv.append(acc_tscv)\n",
    "        sim_pre_tscv.append(pre_tscv)\n",
    "        sim_rec_tscv.append(rec_tscv)\n",
    "        sim_f1_tscv.append(f1_tscv)\n",
    "    \n",
    "    # Save Data -- LAG Loop\n",
    "    lag_acc_tscv.append(np.mean(sim_acc_tscv))\n",
    "    lag_pre_tscv.append(np.mean(sim_pre_tscv))\n",
    "    lag_rec_tscv.append(np.mean(sim_rec_tscv))\n",
    "    lag_f1_tscv.append(np.mean(sim_f1_tscv))\n",
    "    \n",
    "    # Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "    #print(lag_acc_tscv)\n",
    "    #print(lag_pre_tscv)\n",
    "    #print(lag_rec_tscv)\n",
    "    #print(lag_f1_tscv)\n",
    "\n",
    "end_full_tscv = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"full time: \", (end_full_tscv-start_full_tscv)* 10**3, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f894f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(lag_acc_tscv,3))\n",
    "print(lag_pre_tscv)\n",
    "print(lag_rec_tscv)\n",
    "print(lag_f1_tscv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e8aa70",
   "metadata": {},
   "source": [
    "<span style='background :skyblue' > BCV </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93e988",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_full_bcv = time.time()\n",
    "\n",
    "lag_acc_bcv = []\n",
    "lag_pre_bcv = []\n",
    "lag_rec_bcv = []\n",
    "lag_f1_bcv = []\n",
    "lag_vi_bcv = []\n",
    "\n",
    "for d, r in zip(lag_df, range(n_rests)):\n",
    "    sim_acc_bcv = []\n",
    "    sim_pre_bcv = []\n",
    "    sim_rec_bcv = []\n",
    "    sim_f1_bcv = []\n",
    "    sim_vi_bcv = []\n",
    "    \n",
    "    target = d.columns[0]\n",
    "    \n",
    "    for sim in range(n_sims):\n",
    "        #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "        acc_bcv, pre_bcv, rec_bcv, f1_bcv = tree_classification_cv(d, target, cv = 2, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "        # Save data -- SIM\n",
    "        sim_acc_bcv.append(acc_bcv)\n",
    "        sim_pre_bcv.append(pre_bcv)\n",
    "        sim_rec_bcv.append(rec_bcv)\n",
    "        sim_f1_bcv.append(f1_bcv)\n",
    "    \n",
    "    # Save Data -- LAG Loop\n",
    "    lag_acc_bcv.append(np.mean(sim_acc_bcv))\n",
    "    lag_pre_bcv.append(np.mean(sim_pre_bcv))\n",
    "    lag_rec_bcv.append(np.mean(sim_rec_bcv))\n",
    "    lag_f1_bcv.append(np.mean(sim_f1_bcv))\n",
    "    \n",
    "    # Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "    #print(lag_acc_bcv)\n",
    "    #print(lag_pre_bcv)\n",
    "    #print(lag_rec_bcv)\n",
    "    #print(lag_f1_bcv)\n",
    "\n",
    "end_full_bcv = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc404dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"full time: \", (end_full_bcv-start_full_bcv)* 10**3, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b218460",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.round(lag_acc_bcv,3))\n",
    "print(lag_pre_bcv)\n",
    "print(lag_rec_bcv)\n",
    "print(lag_f1_bcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771ee06",
   "metadata": {},
   "source": [
    "##### <span style='background :yellow' > Select best Nlags and CV Type </span>\n",
    "\n",
    "##### <span style='background :yellow' > Need to make huge Simulation... a lot of time</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000c65d5",
   "metadata": {},
   "source": [
    "### <span style='background :orange' > About checking time features and ciclycal values, we will use the results concluded from the first experiment N_Streams_Prediction </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a031669f",
   "metadata": {},
   "source": [
    "# <span style='background :orange' > Is best base model??? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83dbafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "582743ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End total time\n",
    "end_full_infi = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "123f6a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full time:  -1679556165061.5093 ms\n"
     ]
    }
   ],
   "source": [
    "print(\"full time: \", end_full_infi-start_full_infi * 10**3, 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b7af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8bea4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f03e7b9a",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Create TF </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8fdf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_features(df, f=0):\n",
    "    df = df.copy()\n",
    "    if f == 0:\n",
    "        df['year'] = df.index.year\n",
    "        df['quarter'] = df.index.quarter\n",
    "        df['month'] = df.index.month\n",
    "        df['week'] = df.index.isocalendar().week\n",
    "        df['day'] = df.index.day\n",
    "        df['dayofyear'] = df.index.dayofyear\n",
    "        df['dayofweek'] = df.index.dayofweek\n",
    "    \n",
    "        df['is_month_end'] = df.index.is_month_end\n",
    "        df['is_month_start'] = df.index.is_month_start\n",
    "        df['is_cuarter_end'] = df.index.is_quarter_end\n",
    "        df['is_cuarter_start'] = df.index.is_quarter_start\n",
    "        df['is_year_start'] = df.index.is_year_start\n",
    "    \n",
    "    if f == 1:\n",
    "        df['year'] = df.index.year\n",
    "        df['quarter'] = df.index.quarter\n",
    "        df['month'] = df.index.month\n",
    "        df['week'] = df.index.isocalendar().week\n",
    "        df['day'] = df.index.day\n",
    "        df['dayofyear'] = df.index.dayofyear\n",
    "        df['dayofweek'] = df.index.dayofweek\n",
    "        \n",
    "    if f == 2:\n",
    "        df['day'] = df.index.day\n",
    "        df['dayofyear'] = df.index.dayofyear\n",
    "        df['dayofweek'] = df.index.dayofweek\n",
    "        df['year'] = df.index.year\n",
    "        \n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c10423",
   "metadata": {},
   "source": [
    "### <span style='background :lightgreen' > Base </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad00ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar Dataframe con mejores lags\n",
    "# Crear Diferentes 3 sets de TF\n",
    "dftf1 = create_time_features(lag_df[2])\n",
    "dftf2 = create_time_features(lag_df[2], f = 1)\n",
    "dftf3 = create_time_features(lag_df[2], f = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a710cb",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF1 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2daee11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 53s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full = time.time()\n",
    "\n",
    "lag_acc1 = []\n",
    "lag_pre1 = []\n",
    "lag_rec1 = []\n",
    "lag_f11 = []\n",
    "lag_vi1 = []\n",
    "\n",
    "sim_acc1 = []\n",
    "sim_pre1 = []\n",
    "sim_rec1 = []\n",
    "sim_f11 = []\n",
    "sim_vi1 = []\n",
    "    \n",
    "target = dftf1.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc1, pre1, rec1, f11, vi1 = tree_feature_importance_class(dftf1, target, split=n_rests, plot = 3, r = 1)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc1.append(acc1)\n",
    "    sim_pre1.append(pre1)\n",
    "    sim_rec1.append(rec1)\n",
    "    sim_f11.append(f11)\n",
    "    sim_vi1.append(vi1)\n",
    "        \n",
    "        \n",
    "mean_sim_vi = pd.DataFrame(columns = ['feature', 'importance'])\n",
    "\n",
    "# Loop to make variable importance simulation mean\n",
    "for i,col in zip(range(sim_vi[0].shape[0]), sim_vi[0]['feature']):\n",
    "    aux = []\n",
    "    \n",
    "    for j in range(n_sims):\n",
    "        aux.append(sim_vi[j]['importance'][i])\n",
    "    \n",
    "    mean_sim_vi.loc[i, 'feature'] = col\n",
    "    mean_sim_vi.loc[i, 'importance'] = np.mean(aux)\n",
    "\n",
    "#print('\\n Mean Variable Importance LAGS DATAFRAMES \\n')\n",
    "#mean_sim_vi.head()\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc1.append(np.mean(sim_acc1))\n",
    "lag_pre1.append(np.mean(sim_pre1))\n",
    "lag_rec1.append(np.mean(sim_rec1))\n",
    "lag_f11.append(np.mean(sim_f11))\n",
    "lag_vi1.append(mean_sim_vi)\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc)\n",
    "#print(lag_pre)\n",
    "#print(lag_rec)\n",
    "#print(lag_f1)\n",
    "#print(lag_vi)\n",
    "\n",
    "end_full = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f30508",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF2 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58b349ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 21s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full = time.time()\n",
    "\n",
    "lag_acc2 = []\n",
    "lag_pre2 = []\n",
    "lag_rec2 = []\n",
    "lag_f22 = []\n",
    "lag_vi2 = []\n",
    "\n",
    "sim_acc2 = []\n",
    "sim_pre2 = []\n",
    "sim_rec2 = []\n",
    "sim_f22 = []\n",
    "sim_vi2 = []\n",
    "    \n",
    "target = dftf2.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc2, pre2, rec2, f22, vi2 = tree_feature_importance_class(dftf2, target, split=n_rests, plot = 3, r = 1)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc2.append(acc2)\n",
    "    sim_pre2.append(pre2)\n",
    "    sim_rec2.append(rec2)\n",
    "    sim_f22.append(f22)\n",
    "    sim_vi2.append(vi2)\n",
    "        \n",
    "        \n",
    "mean_sim_vi = pd.DataFrame(columns = ['feature', 'importance'])\n",
    "\n",
    "# Loop to make variable importance simulation mean\n",
    "for i,col in zip(range(sim_vi[0].shape[0]), sim_vi[0]['feature']):\n",
    "    aux = []\n",
    "    \n",
    "    for j in range(n_sims):\n",
    "        aux.append(sim_vi[j]['importance'][i])\n",
    "    \n",
    "    mean_sim_vi.loc[i, 'feature'] = col\n",
    "    mean_sim_vi.loc[i, 'importance'] = np.mean(aux)\n",
    "\n",
    "#print('\\n Mean Variable Importance LAGS DATAFRAMES \\n')\n",
    "#mean_sim_vi.head()\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc2.append(np.mean(sim_acc2))\n",
    "lag_pre2.append(np.mean(sim_pre2))\n",
    "lag_rec2.append(np.mean(sim_rec2))\n",
    "lag_f22.append(np.mean(sim_f22))\n",
    "lag_vi2.append(mean_sim_vi)\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc)\n",
    "#print(lag_pre)\n",
    "#print(lag_rec)\n",
    "#print(lag_f2)\n",
    "#print(lag_vi)\n",
    "\n",
    "end_full = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321394c5",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF3 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a891b656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full = time.time()\n",
    "\n",
    "lag_acc3 = []\n",
    "lag_pre3 = []\n",
    "lag_rec3 = []\n",
    "lag_f33 = []\n",
    "lag_vi3 = []\n",
    "\n",
    "sim_acc3 = []\n",
    "sim_pre3 = []\n",
    "sim_rec3 = []\n",
    "sim_f33 = []\n",
    "sim_vi3 = []\n",
    "    \n",
    "target = dftf3.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc3, pre3, rec3, f33, vi3 = tree_feature_importance_class(dftf3, target, split=n_rests, plot = 3, r = 1)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc3.append(acc3)\n",
    "    sim_pre3.append(pre3)\n",
    "    sim_rec3.append(rec3)\n",
    "    sim_f33.append(f33)\n",
    "    sim_vi3.append(vi3)\n",
    "        \n",
    "        \n",
    "mean_sim_vi = pd.DataFrame(columns = ['feature', 'importance'])\n",
    "\n",
    "# Loop to make variable importance simulation mean\n",
    "for i,col in zip(range(sim_vi[0].shape[0]), sim_vi[0]['feature']):\n",
    "    aux = []\n",
    "    \n",
    "    for j in range(n_sims):\n",
    "        aux.append(sim_vi[j]['importance'][i])\n",
    "    \n",
    "    mean_sim_vi.loc[i, 'feature'] = col\n",
    "    mean_sim_vi.loc[i, 'importance'] = np.mean(aux)\n",
    "\n",
    "#print('\\n Mean Variable Importance LAGS DATAFRAMES \\n')\n",
    "#mean_sim_vi.head()\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc3.append(np.mean(sim_acc3))\n",
    "lag_pre3.append(np.mean(sim_pre3))\n",
    "lag_rec3.append(np.mean(sim_rec3))\n",
    "lag_f33.append(np.mean(sim_f33))\n",
    "lag_vi3.append(mean_sim_vi)\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc)\n",
    "#print(lag_pre)\n",
    "#print(lag_rec)\n",
    "#print(lag_f3)\n",
    "#print(lag_vi)\n",
    "\n",
    "end_full = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a9a4d4",
   "metadata": {},
   "source": [
    "### <span style='background :lightgreen' > TSCV </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f22a0",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF1 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffbfc944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20min 52s\n",
      "Wall time: 59min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_tscv1 = time.time()\n",
    "\n",
    "lag_acc_tscv1 = []\n",
    "lag_pre_tscv1 = []\n",
    "lag_rec_tscv1 = []\n",
    "lag_f1_tscv1 = []\n",
    "lag_vi_tscv1 = []\n",
    "\n",
    "sim_acc_tscv1 = []\n",
    "sim_pre_tscv1 = []\n",
    "sim_rec_tscv1 = []\n",
    "sim_f1_tscv1 = []\n",
    "sim_vi_tscv1 = []\n",
    "    \n",
    "target = dftf1.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc_tscv1, pre_tscv1, rec_tscv1, f1_tscv1 = tree_classification_cv(dftf1, target, cv = 1, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc_tscv1.append(acc_tscv1)\n",
    "    sim_pre_tscv1.append(pre_tscv1)\n",
    "    sim_rec_tscv1.append(rec_tscv1)\n",
    "    sim_f1_tscv1.append(f1_tscv1)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc_tscv1.append(np.mean(sim_acc_tscv1))\n",
    "lag_pre_tscv1.append(np.mean(sim_pre_tscv1))\n",
    "lag_rec_tscv1.append(np.mean(sim_rec_tscv1))\n",
    "lag_f1_tscv1.append(np.mean(sim_f1_tscv1))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc_tscv1)\n",
    "#print(lag_pre_tscv1)\n",
    "#print(lag_rec_tscv1)\n",
    "#print(lag_f1_tscv1)\n",
    "\n",
    "end_full_tscv1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bc89d5",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF2 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de8fb178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 20min 13s\n",
      "Wall time: 1h 7min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_tscv2 = time.time()\n",
    "\n",
    "lag_acc_tscv2 = []\n",
    "lag_pre_tscv2 = []\n",
    "lag_rec_tscv2 = []\n",
    "lag_f1_tscv2 = []\n",
    "lag_vi_tscv2 = []\n",
    "\n",
    "sim_acc_tscv2 = []\n",
    "sim_pre_tscv2 = []\n",
    "sim_rec_tscv2 = []\n",
    "sim_f1_tscv2 = []\n",
    "sim_vi_tscv2 = []\n",
    "    \n",
    "target = dftf1.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc_tscv2, pre_tscv2, rec_tscv2, f1_tscv2 = tree_classification_cv(dftf1, target, cv = 1, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc_tscv2.append(acc_tscv2)\n",
    "    sim_pre_tscv2.append(pre_tscv2)\n",
    "    sim_rec_tscv2.append(rec_tscv2)\n",
    "    sim_f1_tscv2.append(f1_tscv2)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc_tscv2.append(np.mean(sim_acc_tscv2))\n",
    "lag_pre_tscv2.append(np.mean(sim_pre_tscv2))\n",
    "lag_rec_tscv2.append(np.mean(sim_rec_tscv2))\n",
    "lag_f1_tscv2.append(np.mean(sim_f1_tscv2))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc_tscv2)\n",
    "#print(lag_pre_tscv2)\n",
    "#print(lag_rec_tscv2)\n",
    "#print(lag_f1_tscv2)\n",
    "\n",
    "end_full_tscv2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a779df0",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF3 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88e9fdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 27min 17s\n",
      "Wall time: 1h 11min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_tscv3 = time.time()\n",
    "\n",
    "lag_acc_tscv3 = []\n",
    "lag_pre_tscv3 = []\n",
    "lag_rec_tscv3 = []\n",
    "lag_f1_tscv3 = []\n",
    "lag_vi_tscv3 = []\n",
    "\n",
    "sim_acc_tscv3 = []\n",
    "sim_pre_tscv3 = []\n",
    "sim_rec_tscv3 = []\n",
    "sim_f1_tscv3 = []\n",
    "sim_vi_tscv3 = []\n",
    "    \n",
    "target = dftf1.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc_tscv3, pre_tscv3, rec_tscv3, f1_tscv3 = tree_classification_cv(dftf1, target, cv = 1, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc_tscv3.append(acc_tscv3)\n",
    "    sim_pre_tscv3.append(pre_tscv3)\n",
    "    sim_rec_tscv3.append(rec_tscv3)\n",
    "    sim_f1_tscv3.append(f1_tscv3)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc_tscv3.append(np.mean(sim_acc_tscv3))\n",
    "lag_pre_tscv3.append(np.mean(sim_pre_tscv3))\n",
    "lag_rec_tscv3.append(np.mean(sim_rec_tscv3))\n",
    "lag_f1_tscv3.append(np.mean(sim_f1_tscv3))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc_tscv3)\n",
    "#print(lag_pre_tscv3)\n",
    "#print(lag_rec_tscv3)\n",
    "#print(lag_f1_tscv3)\n",
    "\n",
    "end_full_tscv3 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4bc76",
   "metadata": {},
   "source": [
    "### <span style='background :lightgreen' > BCV </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6dccea",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF1 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b65b59b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 45s\n",
      "Wall time: 4min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_bcv1 = time.time()\n",
    "\n",
    "lag_acc_bcv1 = []\n",
    "lag_pre_bcv1 = []\n",
    "lag_rec_bcv1 = []\n",
    "lag_f1_bcv1 = []\n",
    "lag_vi_bcv1 = []\n",
    "\n",
    "sim_acc_bcv1 = []\n",
    "sim_pre_bcv1 = []\n",
    "sim_rec_bcv1 = []\n",
    "sim_f1_bcv1 = []\n",
    "sim_vi_bcv1 = []\n",
    "    \n",
    "target = dftf1.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc_bcv1, pre_bcv1, rec_bcv1, f1_bcv1 = tree_classification_cv(dftf1, target, cv = 2, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc_bcv1.append(acc_bcv1)\n",
    "    sim_pre_bcv1.append(pre_bcv1)\n",
    "    sim_rec_bcv1.append(rec_bcv1)\n",
    "    sim_f1_bcv1.append(f1_bcv1)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc_bcv1.append(np.mean(sim_acc_bcv1))\n",
    "lag_pre_bcv1.append(np.mean(sim_pre_bcv1))\n",
    "lag_rec_bcv1.append(np.mean(sim_rec_bcv1))\n",
    "lag_f1_bcv1.append(np.mean(sim_f1_bcv1))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc_bcv1)\n",
    "#print(lag_pre_bcv1)\n",
    "#print(lag_rec_bcv1)\n",
    "#print(lag_f1_bcv1)\n",
    "\n",
    "end_full_bcv1 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb2a931",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF2 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e850dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 26s\n",
      "Wall time: 3min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_bcv2 = time.time()\n",
    "\n",
    "lag_acc_bcv2 = []\n",
    "lag_pre_bcv2 = []\n",
    "lag_rec_bcv2 = []\n",
    "lag_f1_bcv2 = []\n",
    "lag_vi_bcv2 = []\n",
    "\n",
    "sim_acc_bcv2 = []\n",
    "sim_pre_bcv2 = []\n",
    "sim_rec_bcv2 = []\n",
    "sim_f1_bcv2 = []\n",
    "sim_vi_bcv2 = []\n",
    "    \n",
    "target = dftf2.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc_bcv2, pre_bcv2, rec_bcv2, f1_bcv2 = tree_classification_cv(dftf2, target, cv = 2, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc_bcv2.append(acc_bcv2)\n",
    "    sim_pre_bcv2.append(pre_bcv2)\n",
    "    sim_rec_bcv2.append(rec_bcv2)\n",
    "    sim_f1_bcv2.append(f1_bcv2)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc_bcv2.append(np.mean(sim_acc_bcv2))\n",
    "lag_pre_bcv2.append(np.mean(sim_pre_bcv2))\n",
    "lag_rec_bcv2.append(np.mean(sim_rec_bcv2))\n",
    "lag_f1_bcv2.append(np.mean(sim_f1_bcv2))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc_bcv2)\n",
    "#print(lag_pre_bcv2)\n",
    "#print(lag_rec_bcv2)\n",
    "#print(lag_f1_bcv2)\n",
    "\n",
    "end_full_bcv2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86caa914",
   "metadata": {},
   "source": [
    "### <span style=\"background:skyblue\"> TF3 <span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb7cb911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 10s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_full_bcv3 = time.time()\n",
    "\n",
    "lag_acc_bcv3 = []\n",
    "lag_pre_bcv3 = []\n",
    "lag_rec_bcv3 = []\n",
    "lag_f1_bcv3 = []\n",
    "lag_vi_bcv3 = []\n",
    "\n",
    "sim_acc_bcv3 = []\n",
    "sim_pre_bcv3 = []\n",
    "sim_rec_bcv3 = []\n",
    "sim_f1_bcv3 = []\n",
    "sim_vi_bcv3 = []\n",
    "    \n",
    "target = dftf3.columns[0]\n",
    "    \n",
    "for sim in range(n_sims):\n",
    "    #print('-----------------', target, '- sim n:', sim, '- lag: ', r, '-------------------')\n",
    "    acc_bcv3, pre_bcv3, rec_bcv3, f1_bcv3 = tree_classification_cv(dftf3, target, cv = 2, cv_split = n_split, test_size = n_rests)\n",
    "        \n",
    "    # Save data -- SIM\n",
    "    sim_acc_bcv3.append(acc_bcv3)\n",
    "    sim_pre_bcv3.append(pre_bcv3)\n",
    "    sim_rec_bcv3.append(rec_bcv3)\n",
    "    sim_f1_bcv3.append(f1_bcv3)\n",
    "    \n",
    "# Save Data -- LAG Loop\n",
    "lag_acc_bcv3.append(np.mean(sim_acc_bcv3))\n",
    "lag_pre_bcv3.append(np.mean(sim_pre_bcv3))\n",
    "lag_rec_bcv3.append(np.mean(sim_rec_bcv3))\n",
    "lag_f1_bcv3.append(np.mean(sim_f1_bcv3))\n",
    "    \n",
    "# Save Data -- VARIABLES/FEATURES\n",
    "\n",
    "#print(lag_acc_bcv3)\n",
    "#print(lag_pre_bcv3)\n",
    "#print(lag_rec_bcv3)\n",
    "#print(lag_f1_bcv3)\n",
    "\n",
    "end_full_bcv3 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7785d3",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df960a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 0 BCV: rest_type :  0.7332933333333334\n",
      "TF 1 BCV: rest_type :  0.7444\n",
      "TF 2 BCV: rest_type :  0.7066933333333334\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mae, d1, mae1, d2, mae2 in zip(lag_acc1, dftf2, lag_acc2, dftf3, lag_acc3):\n",
    "    print('TF 0 BCV:',str(dftf1.columns[0]), ': ', mae)\n",
    "    print('TF 1 BCV:', str(dftf2.columns[0]), ': ', mae1)\n",
    "    print('TF 2 BCV:',str(dftf3.columns[0]), ': ', mae2)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de3d588c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 0 BCV: rest_type :  0.3393650793650795\n",
      "TF 1 BCV: rest_type :  0.3376190476190476\n",
      "TF 2 BCV: rest_type :  0.3453968253968254\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mae, d1, mae1, d2, mae2 in zip(lag_acc_tscv1, dftf2, lag_acc_tscv2, dftf3, lag_acc_tscv3):\n",
    "    print('TF 0 BCV:',str(dftf1.columns[0]), ': ', mae)\n",
    "    print('TF 1 BCV:', str(dftf2.columns[0]), ': ', mae1)\n",
    "    print('TF 2 BCV:',str(dftf3.columns[0]), ': ', mae2)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb59606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF 0 BCV: rest_type :  0.26650793650793647\n",
      "TF 1 BCV: rest_type :  0.25761904761904764\n",
      "TF 2 BCV: rest_type :  0.25587301587301586\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mae, d1, mae1, d2, mae2 in zip(lag_acc_bcv1, dftf2, lag_acc_bcv2, dftf3, lag_acc_bcv3):\n",
    "    print('TF 0 BCV:',str(dftf1.columns[0]), ': ', mae)\n",
    "    print('TF 1 BCV:', str(dftf2.columns[0]), ': ', mae1)\n",
    "    print('TF 2 BCV:',str(dftf3.columns[0]), ': ', mae2)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493d078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a1c114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
